{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2b8770c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "export_conn = pyodbc.connect(\n",
    "    'DRIVER={ODBC Driver 17 for SQL Server};'\n",
    "    'SERVER=(localdb)\\\\MSSQLLocalDB;'\n",
    "    'DATABASE=projectdatawarehouse;'\n",
    "    'Trusted_Connection=yes;'\n",
    ")\n",
    "\n",
    "export_cursor = export_conn.cursor()\n",
    "\n",
    "import_conn = pyodbc.connect(\n",
    "    'DRIVER={ODBC Driver 17 for SQL Server};'\n",
    "    'SERVER=(localdb)\\\\MSSQLLocalDB;'\n",
    "    'DATABASE=projectsourcedatamodel;'\n",
    "    'Trusted_Connection=yes;'\n",
    ")\n",
    "\n",
    "import_cursor = import_conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "309ac568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alle tabellen zijn geleegd.\n"
     ]
    }
   ],
   "source": [
    "def clear_tables():\n",
    "    tables = [\n",
    "        'Fact_EmployeePerformance',\n",
    "        'Fact_Sales',\n",
    "        'Fact_Purchase',\n",
    "        'Dim_Employee',\n",
    "        'Dim_Location',\n",
    "        'Dim_DateTime',\n",
    "        'Dim_Product',\n",
    "        'Dim_Customer'\n",
    "    ]\n",
    "\n",
    "    for table in tables:\n",
    "        export_cursor.execute(f\"DELETE FROM {table}\")\n",
    "        export_conn.commit()\n",
    "\n",
    "    print(\"Alle tabellen zijn geleegd.\")\n",
    "\n",
    "clear_tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3a361800",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ibrah\\AppData\\Local\\Temp\\ipykernel_19704\\3898742451.py:2: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  customer = pd.read_sql_query(\"SELECT CustomerID, Fname, Lname, Phone, Address, City, Region, State, Country FROM Customer\", import_conn)\n",
      "C:\\Users\\ibrah\\AppData\\Local\\Temp\\ipykernel_19704\\3898742451.py:3: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  customer_customer_demo = pd.read_sql_query(\"SELECT CustomerID, CustomerTypeID FROM CustomerCustomerDemo\", import_conn)\n",
      "C:\\Users\\ibrah\\AppData\\Local\\Temp\\ipykernel_19704\\3898742451.py:4: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  customer_demographics = pd.read_sql_query(\"SELECT CustomerTypeID, CustomerDesc FROM CustomerDemographics\", import_conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "217 customers verwerkt in Dim_Customer\n"
     ]
    }
   ],
   "source": [
    "def move_dimcustomer(import_conn, export_conn):\n",
    "    customer = pd.read_sql_query(\"SELECT CustomerID, Fname, Lname, Phone, Address, City, Region, State, Country FROM Customer\", import_conn)\n",
    "    customer_customer_demo = pd.read_sql_query(\"SELECT CustomerID, CustomerTypeID FROM CustomerCustomerDemo\", import_conn)\n",
    "    customer_demographics = pd.read_sql_query(\"SELECT CustomerTypeID, CustomerDesc FROM CustomerDemographics\", import_conn)\n",
    "\n",
    "    merged_df = customer.merge(customer_customer_demo, on='CustomerID', how='left')\n",
    "    merged_df = merged_df.merge(customer_demographics, on='CustomerTypeID', how='left')\n",
    "\n",
    "    merged_df['FullName'] = merged_df['Fname'] + ' ' + merged_df['Lname']\n",
    "    merged_df['Region'] = merged_df['Region'].combine_first(merged_df['State']) \n",
    "    \n",
    "    final_df = merged_df[[\n",
    "        'CustomerID', \n",
    "        'FullName', \n",
    "        'CustomerDesc', \n",
    "        'Phone', \n",
    "        'Address', \n",
    "        'City', \n",
    "        'Region', \n",
    "        'Country'\n",
    "    ]].rename(columns={'CustomerDesc': 'CustomerType'})\n",
    "\n",
    "    cursor = export_conn.cursor()\n",
    "    \n",
    "    for index, row in final_df.iterrows():\n",
    "        try:\n",
    "            query = '''\n",
    "                INSERT INTO Dim_Customer \n",
    "                (CustomerID, FullName, CustomerType, PhoneNumber, Address, City, Region, Country) \n",
    "                VALUES (?, ?, ?, ?, ?, ?, ?, ?)\n",
    "            '''\n",
    "            cursor.execute(query, tuple(row.fillna('')))\n",
    "        except Exception as e:\n",
    "            print(f\"Fout bij invoegen customer {row['CustomerID']}: {e}\")\n",
    "    \n",
    "    export_conn.commit()\n",
    "    print(f\"{len(final_df)} customers verwerkt in Dim_Customer\")\n",
    "\n",
    "move_dimcustomer(import_conn, export_conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "382c169f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ibrah\\AppData\\Local\\Temp\\ipykernel_19704\\282512446.py:3: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  sales_customers = pd.read_sql_query(\"SELECT CustomerID FROM Sales_Customer\", import_conn)\n",
      "C:\\Users\\ibrah\\AppData\\Local\\Temp\\ipykernel_19704\\282512446.py:5: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  existing_customers = pd.read_sql_query(\"SELECT CustomerID FROM Dim_Customer\", export_conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19694 nieuwe CustomerID's toegevoegd aan Dim_Customer\n",
      "126 CustomerID's bestonden al en zijn overgeslagen\n"
     ]
    }
   ],
   "source": [
    "def add_sales_customer_ids(import_conn, export_conn):\n",
    "    \n",
    "    sales_customers = pd.read_sql_query(\"SELECT CustomerID FROM Sales_Customer\", import_conn)\n",
    "    \n",
    "    existing_customers = pd.read_sql_query(\"SELECT CustomerID FROM Dim_Customer\", export_conn)\n",
    "\n",
    "    new_customers = sales_customers[~sales_customers['CustomerID'].isin(existing_customers['CustomerID'])]\n",
    "    \n",
    "    cursor = export_conn.cursor()\n",
    "    success_count = 0\n",
    "    \n",
    "    for customer_id in new_customers['CustomerID']:\n",
    "        try:\n",
    "            \n",
    "            query = '''\n",
    "                INSERT INTO Dim_Customer \n",
    "                (CustomerID) \n",
    "                VALUES (?)\n",
    "            '''\n",
    "            cursor.execute(query, (str(customer_id),))  \n",
    "            success_count += 1\n",
    "        except Exception as e:\n",
    "            \n",
    "            pass  \n",
    "    \n",
    "    export_conn.commit()\n",
    "    print(f\"{success_count} nieuwe CustomerID's toegevoegd aan Dim_Customer\")\n",
    "    print(f\"{len(sales_customers) - success_count} CustomerID's bestonden al en zijn overgeslagen\")\n",
    "\n",
    "add_sales_customer_ids(import_conn, export_conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9553e11e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351 employees imported into Dim_Employee\n"
     ]
    }
   ],
   "source": [
    "def move_dimemployee():\n",
    "    import_cursor.execute(\"\"\"\n",
    "        SELECT \n",
    "            e.EmployeeID,\n",
    "            e.FirstName + ' ' + e.LastName AS FullName,\n",
    "            COALESCE(e.JobTitle, e.Title, 'Onbekend') AS JobTitle,\n",
    "            d.dept_name AS Department,\n",
    "            e.HireDate,\n",
    "            e.BirthDate,\n",
    "            NULL AS EmailAddress,\n",
    "            NULL AS ManagerID  \n",
    "        FROM Employee e\n",
    "        LEFT JOIN Department d ON e.DepartmentID = d.dept_id\n",
    "    \"\"\")\n",
    "    \n",
    "    employees = import_cursor.fetchall()\n",
    "    \n",
    "    for employee in employees:\n",
    "        export_cursor.execute(\"\"\"\n",
    "            INSERT INTO Dim_Employee (\n",
    "                EmployeeID,\n",
    "                FullName,\n",
    "                JobTitle,\n",
    "                Department,\n",
    "                HireDate,\n",
    "                BirthDate,\n",
    "                EmailAddress,\n",
    "                ManagerID\n",
    "            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?)\n",
    "        \"\"\", employee)\n",
    "    \n",
    "    import_cursor.execute(\"\"\"\n",
    "        SELECT e.EmployeeID, e.manager_id\n",
    "        FROM Employee e\n",
    "        WHERE e.manager_id IS NOT NULL\n",
    "    \"\"\")\n",
    "    \n",
    "    manager_pairs = import_cursor.fetchall()\n",
    "    \n",
    "    for emp_id, manager_id in manager_pairs:\n",
    "        export_cursor.execute(\"\"\"\n",
    "            UPDATE Dim_Employee\n",
    "            SET ManagerID = ?\n",
    "            WHERE EmployeeID = ?\n",
    "            AND EXISTS (SELECT 1 FROM Dim_Employee WHERE EmployeeID = ?)  \n",
    "        \"\"\", (manager_id, emp_id, manager_id))\n",
    "    \n",
    "    export_conn.commit()\n",
    "    print(f\"{len(employees)} employees imported into Dim_Employee\")\n",
    "\n",
    "move_dimemployee()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "870ce7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ibrah\\AppData\\Local\\Temp\\ipykernel_19704\\1238095902.py:2: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  product = pd.read_sql_query(\"\"\"\n",
      "C:\\Users\\ibrah\\AppData\\Local\\Temp\\ipykernel_19704\\1238095902.py:15: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  category = pd.read_sql_query(\"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "585 products verwerkt in Dim_Product\n"
     ]
    }
   ],
   "source": [
    "def move_dimproduct(import_conn, export_conn):\n",
    "    product = pd.read_sql_query(\"\"\"\n",
    "        SELECT \n",
    "            ProductID, \n",
    "            Name AS ProductName,\n",
    "            Color,\n",
    "            StandardCost,\n",
    "            ListPrice,\n",
    "            ProductLine,\n",
    "            Discontinued,\n",
    "            CategoryID\n",
    "        FROM Product\n",
    "    \"\"\", import_conn)\n",
    "    \n",
    "    category = pd.read_sql_query(\"\"\"\n",
    "        SELECT \n",
    "            CategoryID, \n",
    "            CategoryName AS ProductCategoryName\n",
    "        FROM Category\n",
    "    \"\"\", import_conn)\n",
    "    \n",
    "    merged_df = product.merge(category, on='CategoryID', how='left')\n",
    "    \n",
    "    merged_df['DiscontinuedDate'] = merged_df['Discontinued'].apply(\n",
    "        lambda x: pd.Timestamp.today().date() if x == 1 else None\n",
    "    )\n",
    "\n",
    "    final_df = merged_df[[\n",
    "        'ProductID', \n",
    "        'ProductName', \n",
    "        'ProductCategoryName', \n",
    "        'Color', \n",
    "        'StandardCost', \n",
    "        'ListPrice', \n",
    "        'ProductLine', \n",
    "        'DiscontinuedDate'\n",
    "    ]]\n",
    " \n",
    "    cursor = export_conn.cursor()\n",
    "    \n",
    "    for index, row in final_df.iterrows():\n",
    "        try:\n",
    "            query = '''\n",
    "                INSERT INTO Dim_Product \n",
    "                (ProductID, ProductName, ProductCategoryName, Color, \n",
    "                 StandardCost, ListPrice, ProductLine, DiscontinuedDate) \n",
    "                SELECT ?, ?, ?, ?, ?, ?, ?, ?\n",
    "                WHERE NOT EXISTS (\n",
    "                    SELECT 1 FROM Dim_Product WHERE ProductID = ?\n",
    "                )\n",
    "            '''\n",
    "            values = tuple(row.fillna('') if isinstance(row, pd.Series) else row) + (row['ProductID'],)\n",
    "            cursor.execute(query, values)\n",
    "        except Exception as e:\n",
    "            print(f\"Fout bij invoegen product {row['ProductID']}: {e}\")\n",
    "    \n",
    "    export_conn.commit()\n",
    "    print(f\"{len(final_df)} products verwerkt in Dim_Product\")\n",
    "\n",
    "# Roep de functie aan\n",
    "move_dimproduct(import_conn, export_conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4f37b6b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ibrah\\AppData\\Local\\Temp\\ipykernel_19704\\2605678959.py:2: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  customer = pd.read_sql_query(\"SELECT CustomerID, Address AS StreetAddress, City, State FROM Customer\", import_conn)\n",
      "C:\\Users\\ibrah\\AppData\\Local\\Temp\\ipykernel_19704\\2605678959.py:3: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  state = pd.read_sql_query(\"SELECT State_id, State_name AS StateProvince, Country FROM State\", import_conn)\n",
      "C:\\Users\\ibrah\\AppData\\Local\\Temp\\ipykernel_19704\\2605678959.py:4: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  order = pd.read_sql_query(\"SELECT OrderID, CustomerID, EmployeeID FROM [Order]\", import_conn)\n",
      "C:\\Users\\ibrah\\AppData\\Local\\Temp\\ipykernel_19704\\2605678959.py:5: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  employee = pd.read_sql_query(\"SELECT EmployeeID, PostalCode FROM Employee\", import_conn)\n",
      "C:\\Users\\ibrah\\AppData\\Local\\Temp\\ipykernel_19704\\2605678959.py:6: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  emp_terr = pd.read_sql_query(\"SELECT EmployeeID, TerritoryID FROM EmployeeTerritories\", import_conn)\n",
      "C:\\Users\\ibrah\\AppData\\Local\\Temp\\ipykernel_19704\\2605678959.py:7: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  territories = pd.read_sql_query(\"SELECT TerritoryID, RegionID FROM Territories\", import_conn)\n",
      "C:\\Users\\ibrah\\AppData\\Local\\Temp\\ipykernel_19704\\2605678959.py:8: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  region = pd.read_sql_query(\"SELECT RegionID, RegionDescription AS Region FROM Region\", import_conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "464 locaties verwerkt in Dim_Location\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def move_dimlocation(import_conn, export_conn):\n",
    "    customer = pd.read_sql_query(\"SELECT CustomerID, Address AS StreetAddress, City, State FROM Customer\", import_conn)\n",
    "    state = pd.read_sql_query(\"SELECT State_id, State_name AS StateProvince, Country FROM State\", import_conn)\n",
    "    order = pd.read_sql_query(\"SELECT OrderID, CustomerID, EmployeeID FROM [Order]\", import_conn)\n",
    "    employee = pd.read_sql_query(\"SELECT EmployeeID, PostalCode FROM Employee\", import_conn)\n",
    "    emp_terr = pd.read_sql_query(\"SELECT EmployeeID, TerritoryID FROM EmployeeTerritories\", import_conn)\n",
    "    territories = pd.read_sql_query(\"SELECT TerritoryID, RegionID FROM Territories\", import_conn)\n",
    "    region = pd.read_sql_query(\"SELECT RegionID, RegionDescription AS Region FROM Region\", import_conn)\n",
    "\n",
    "    df = customer.merge(state, left_on='State', right_on='State_id', how='left') \\\n",
    "                 .merge(order, on='CustomerID', how='inner') \\\n",
    "                 .merge(employee, on='EmployeeID', how='inner') \\\n",
    "                 .merge(emp_terr, on='EmployeeID', how='inner') \\\n",
    "                 .merge(territories, on='TerritoryID', how='inner') \\\n",
    "                 .merge(region, on='RegionID', how='inner')\n",
    "\n",
    "    final_df = df[[\n",
    "        'StreetAddress', \n",
    "        'City', \n",
    "        'StateProvince', \n",
    "        'Region', \n",
    "        'Country', \n",
    "        'PostalCode'\n",
    "    ]].drop_duplicates()\n",
    "\n",
    "    cursor = export_conn.cursor()\n",
    "\n",
    "    for index, row in final_df.iterrows():\n",
    "        try:\n",
    "            query = '''\n",
    "                INSERT INTO Dim_Location \n",
    "                (StreetAddress, City, StateProvince, Region, Country, PostalCode)\n",
    "                VALUES (?, ?, ?, ?, ?, ?)\n",
    "            '''\n",
    "            cursor.execute(query, tuple(row.fillna('')))\n",
    "        except Exception as e:\n",
    "            print(f\"Fout bij invoegen customer {row['LocationID']}: {e}\")\n",
    "\n",
    "    export_conn.commit()\n",
    "    print(f\"{len(final_df)} locaties verwerkt in Dim_Location\")\n",
    "\n",
    "move_dimlocation(import_conn, export_conn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7cc712dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ibrah\\AppData\\Local\\Temp\\ipykernel_19704\\3903326268.py:3: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_salesorderdate = pd.read_sql_query(\"\"\"\n",
      "C:\\Users\\ibrah\\AppData\\Local\\Temp\\ipykernel_19704\\3903326268.py:13: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_purchaseorderdate = pd.read_sql_query(\"\"\"\n",
      "C:\\Users\\ibrah\\AppData\\Local\\Temp\\ipykernel_19704\\3903326268.py:23: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_bonusdate = pd.read_sql_query(\"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1424 unieke datums verwerkt in Dim_DateTime\n"
     ]
    }
   ],
   "source": [
    "def move_datetime(import_conn, export_conn):\n",
    "    # Haal datumdata op uit alle relevante bronnen\n",
    "    df_salesorderdate = pd.read_sql_query(\"\"\"\n",
    "        SELECT \n",
    "            OrderDate AS Date,\n",
    "            YEAR(OrderDate) AS Year,\n",
    "            DATEPART(QUARTER, OrderDate) AS Quarter,\n",
    "            MONTH(OrderDate) AS Month,\n",
    "            DAY(OrderDate) AS Day\n",
    "        FROM Sales_SalesOrderHeader\n",
    "    \"\"\", import_conn)\n",
    "    \n",
    "    df_purchaseorderdate = pd.read_sql_query(\"\"\"\n",
    "        SELECT \n",
    "            OrderDate AS Date,\n",
    "            YEAR(OrderDate) AS Year,\n",
    "            DATEPART(QUARTER, OrderDate) AS Quarter,\n",
    "            MONTH(OrderDate) AS Month,\n",
    "            DAY(OrderDate) AS Day\n",
    "        FROM Purchasing_PurchaseOrderHeader\n",
    "    \"\"\", import_conn)\n",
    "    \n",
    "    df_bonusdate = pd.read_sql_query(\"\"\"\n",
    "        SELECT \n",
    "            Bonus_date AS Date,\n",
    "            YEAR(Bonus_date) AS Year,\n",
    "            DATEPART(QUARTER, Bonus_date) AS Quarter,\n",
    "            MONTH(Bonus_date) AS Month,\n",
    "            DAY(Bonus_date) AS Day\n",
    "        FROM Bonus\n",
    "    \"\"\", import_conn)\n",
    "\n",
    "    # Combineer alle datums en verwijder duplicaten\n",
    "    unique_dates = pd.concat([df_salesorderdate, df_purchaseorderdate, df_bonusdate]).drop_duplicates(subset=['Date'])\n",
    "    \n",
    "    cursor = export_conn.cursor()\n",
    "\n",
    "    for index, row in unique_dates.iterrows():\n",
    "        try:\n",
    "            query = '''\n",
    "            MERGE INTO Dim_DateTime AS target\n",
    "            USING (SELECT ? AS Date, ? AS Year, ? AS Quarter, ? AS Month, ? AS Day) AS source\n",
    "            ON target.Date = source.Date\n",
    "            WHEN NOT MATCHED THEN\n",
    "                INSERT (Date, Year, Quarter, Month, Day)\n",
    "                VALUES (source.Date, source.Year, source.Quarter, source.Month, source.Day);\n",
    "            '''\n",
    "            cursor.execute(query, (row['Date'], row['Year'], row['Quarter'], row['Month'], row['Day']))\n",
    "        except Exception as e:\n",
    "            print(f\"Fout bij invoegen datum {row['Date']}: {e}\")\n",
    "    \n",
    "    export_conn.commit()\n",
    "    print(f\"{len(unique_dates)} unieke datums verwerkt in Dim_DateTime\")\n",
    "\n",
    "# Roep de functie aan\n",
    "move_datetime(import_conn, export_conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a9802a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ibrah\\AppData\\Local\\Temp\\ipykernel_19704\\2515128060.py:2: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  header = pd.read_sql_query(\"\"\"\n",
      "C:\\Users\\ibrah\\AppData\\Local\\Temp\\ipykernel_19704\\2515128060.py:14: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  detail = pd.read_sql_query(\"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121317 verkopen verwerkt in Fact_Sales\n"
     ]
    }
   ],
   "source": [
    "def move_feitsales(import_conn, export_conn):\n",
    "    header = pd.read_sql_query(\"\"\"\n",
    "        SELECT \n",
    "            SalesOrderID,\n",
    "            OrderDate AS SaleDateID,\n",
    "            CustomerID,\n",
    "            NULL AS LocationID,\n",
    "            Freight,\n",
    "            TaxAmt,\n",
    "            TotalDue\n",
    "        FROM Sales_SalesOrderHeader\n",
    "    \"\"\", import_conn)\n",
    "\n",
    "    detail = pd.read_sql_query(\"\"\"\n",
    "        SELECT \n",
    "            SalesOrderID,\n",
    "            SalesOrderDetailID AS SalesID,\n",
    "            ProductID,\n",
    "            OrderQty AS Quantity,\n",
    "            UnitPrice,\n",
    "            UnitPriceDiscount,\n",
    "            LineTotal\n",
    "        FROM Sales_SalesOrderDetail\n",
    "    \"\"\", import_conn)\n",
    "\n",
    "    merged_df = detail.merge(header, on='SalesOrderID', how='inner')\n",
    "\n",
    "    merged_df['DiscountAmount'] = merged_df['UnitPrice'] * merged_df['UnitPriceDiscount'] * merged_df['Quantity']\n",
    "    merged_df['SalesAmount'] = merged_df['LineTotal'] - merged_df['DiscountAmount']\n",
    "    merged_df['Profit'] = merged_df['TotalDue'] - (merged_df['LineTotal'] / merged_df['TotalDue'])\n",
    "\n",
    "    final_df = merged_df[[\n",
    "        'SalesID',\n",
    "        'SaleDateID',\n",
    "        'ProductID',\n",
    "        'CustomerID',\n",
    "        'LocationID',\n",
    "        'Quantity',\n",
    "        'UnitPrice',\n",
    "        'DiscountAmount',\n",
    "        'SalesAmount',\n",
    "        'TaxAmt',\n",
    "        'TotalDue',\n",
    "        'Profit'\n",
    "    ]]\n",
    "\n",
    "    cursor = export_conn.cursor()\n",
    "    for index, row in final_df.iterrows():\n",
    "        try:\n",
    "            query = '''\n",
    "                INSERT INTO Fact_Sales \n",
    "                (SalesID, SaleDateID, ProductID, CustomerID, LocationID,\n",
    "                 Quantity, UnitPrice, DiscountAmount, SalesAmount, TaxAmount, TotalAmount, Profit)\n",
    "                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "            '''\n",
    "            values = [None if pd.isna(row[col]) else row[col] for col in final_df.columns]\n",
    "            cursor.execute(query, values)\n",
    "        except Exception as e:\n",
    "            print(f\"Fout bij invoegen verkoop (SalesID {row['SalesID']}): {e}\")\n",
    "\n",
    "    export_conn.commit()\n",
    "    print(f\"{len(final_df)} verkopen verwerkt in Fact_Sales\")\n",
    "move_feitsales(import_conn, export_conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6115f044",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ibrah\\AppData\\Local\\Temp\\ipykernel_19704\\1340890757.py:3: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  sales_header = pd.read_sql_query(\"\"\"\n",
      "C:\\Users\\ibrah\\AppData\\Local\\Temp\\ipykernel_19704\\1340890757.py:15: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  sales_detail = pd.read_sql_query(\"\"\"\n",
      "C:\\Users\\ibrah\\AppData\\Local\\Temp\\ipykernel_19704\\1340890757.py:25: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  bonus = pd.read_sql_query(\"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5860 performance records verwerkt in Fact_EmployeePerformance\n"
     ]
    }
   ],
   "source": [
    "def move_feitemployeeperformance(import_conn, export_conn):\n",
    "    # Data ophalen uit de verschillende tabellen\n",
    "    sales_header = pd.read_sql_query(\"\"\"\n",
    "        SELECT \n",
    "            SalesOrderID,\n",
    "            OrderDate,\n",
    "            SalesPersonID AS EmployeeID,\n",
    "            TerritoryID,\n",
    "            SubTotal,\n",
    "            TotalDue\n",
    "        FROM Sales_SalesOrderHeader\n",
    "        WHERE SalesPersonID IS NOT NULL\n",
    "    \"\"\", import_conn)\n",
    "    \n",
    "    sales_detail = pd.read_sql_query(\"\"\"\n",
    "        SELECT \n",
    "            SalesOrderID,\n",
    "            OrderQty,\n",
    "            ProductID,\n",
    "            UnitPrice,\n",
    "            LineTotal\n",
    "        FROM Sales_SalesOrderDetail\n",
    "    \"\"\", import_conn)\n",
    "    \n",
    "    bonus = pd.read_sql_query(\"\"\"\n",
    "        SELECT \n",
    "            Emp_id AS EmployeeID,\n",
    "            Bonus_date,\n",
    "            Bonus_amount AS BonusAmount\n",
    "        FROM Bonus\n",
    "    \"\"\", import_conn)\n",
    "    \n",
    "    sales_merged = sales_header.merge(sales_detail, on='SalesOrderID', how='left')\n",
    "    \n",
    "    sales_merged['OrderDate'] = pd.to_datetime(sales_merged['OrderDate']).dt.date\n",
    "    bonus['Bonus_date'] = pd.to_datetime(bonus['Bonus_date']).dt.date\n",
    "    \n",
    "    # Groepeer sales per werknemer per datum om prestaties te berekenen\n",
    "    performance = sales_merged.groupby(['EmployeeID', 'OrderDate']).agg(\n",
    "        OrderCount=('SalesOrderID', 'nunique'),\n",
    "        TotalSales=('TotalDue', 'sum'),\n",
    "        AvgOrderValue=('TotalDue', 'mean')\n",
    "    ).reset_index()\n",
    "    \n",
    "    # Bereken bonus statistieken per werknemer per datum\n",
    "    bonus_agg = bonus.groupby(['EmployeeID', 'Bonus_date']).agg(\n",
    "        TotalBonus=('BonusAmount', 'sum'),\n",
    "        BonusAmount=('BonusAmount', 'first')\n",
    "    ).reset_index()\n",
    "    \n",
    "    # Maak een complete set van alle unieke datums (zowel OrderDate als Bonus_date)\n",
    "    all_dates = pd.concat([\n",
    "        performance[['EmployeeID', 'OrderDate']].rename(columns={'OrderDate': 'PerformanceDate'}),\n",
    "        bonus_agg[['EmployeeID', 'Bonus_date']].rename(columns={'Bonus_date': 'PerformanceDate'})\n",
    "    ]).drop_duplicates()\n",
    "    \n",
    "    final_df = all_dates.merge(\n",
    "        performance,\n",
    "        left_on=['EmployeeID', 'PerformanceDate'],\n",
    "        right_on=['EmployeeID', 'OrderDate'],\n",
    "        how='left'\n",
    "    ).merge(\n",
    "        bonus_agg,\n",
    "        left_on=['EmployeeID', 'PerformanceDate'],\n",
    "        right_on=['EmployeeID', 'Bonus_date'],\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    final_df['OrderCount'] = final_df['OrderCount'].fillna(0)\n",
    "    final_df['TotalSales'] = final_df['TotalSales'].fillna(0)\n",
    "    final_df['AvgOrderValue'] = final_df['AvgOrderValue'].fillna(0)\n",
    "    final_df['TotalBonus'] = final_df['TotalBonus'].fillna(0)\n",
    "    final_df['BonusAmount'] = final_df['BonusAmount'].fillna(0)\n",
    "\n",
    "    final_df = final_df[[\n",
    "        'PerformanceDate',\n",
    "        'EmployeeID',\n",
    "        'OrderCount',\n",
    "        'TotalBonus',\n",
    "        'BonusAmount',\n",
    "        'AvgOrderValue'\n",
    "    ]].rename(columns={\n",
    "        'PerformanceDate': 'PerformanceDateID'\n",
    "    })\n",
    "    cursor = export_conn.cursor()\n",
    "    \n",
    "    for index, row in final_df.iterrows():\n",
    "        try:\n",
    "            query = '''\n",
    "                INSERT INTO Fact_EmployeePerformance \n",
    "                (PerformanceDateID, EmployeeID, OrderCount, TotalBonus, BonusAmount, AvgOrderValue) \n",
    "                SELECT ?, ?, ?, ?, ?, ?\n",
    "                WHERE NOT EXISTS (\n",
    "                    SELECT 1 FROM Fact_EmployeePerformance \n",
    "                    WHERE PerformanceDateID = ? AND EmployeeID = ?\n",
    "                )\n",
    "            '''\n",
    "            values = (\n",
    "                row['PerformanceDateID'],\n",
    "                row['EmployeeID'],\n",
    "                row['OrderCount'],\n",
    "                row['TotalBonus'],\n",
    "                row['BonusAmount'],\n",
    "                row['AvgOrderValue'],\n",
    "                row['PerformanceDateID'],\n",
    "                row['EmployeeID']\n",
    "            )\n",
    "            cursor.execute(query, values)\n",
    "        except Exception as e:\n",
    "            print(f\"Fout bij invoegen performance data voor werknemer {row['EmployeeID']} op {row['PerformanceDateID']}: {e}\")\n",
    "    \n",
    "    export_conn.commit()\n",
    "    print(f\"{len(final_df)} performance records verwerkt in Fact_EmployeePerformance\")\n",
    "move_feitemployeeperformance(import_conn, export_conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6e1acbd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ibrah\\AppData\\Local\\Temp\\ipykernel_19704\\597606627.py:2: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  purchase_header = pd.read_sql_query(\"\"\"\n",
      "C:\\Users\\ibrah\\AppData\\Local\\Temp\\ipykernel_19704\\597606627.py:15: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  purchase_detail = pd.read_sql_query(\"\"\"\n",
      "C:\\Users\\ibrah\\AppData\\Local\\Temp\\ipykernel_19704\\597606627.py:51: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  existing_ids = pd.read_sql_query(\"SELECT PurchaseID FROM Fact_Purchase\", export_conn)['PurchaseID'].tolist()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4012 nieuwe purchase records toegevoegd aan Fact_Purchase\n"
     ]
    }
   ],
   "source": [
    "def move_feitpurchase(import_conn, export_conn):\n",
    "    purchase_header = pd.read_sql_query(\"\"\"\n",
    "        SELECT \n",
    "            PurchaseOrderID AS PurchaseID,\n",
    "            EmployeeID,\n",
    "            VendorID,\n",
    "            OrderDate,\n",
    "            SubTotal,\n",
    "            TaxAmt,\n",
    "            Freight,\n",
    "            TotalDue\n",
    "        FROM Purchasing_PurchaseOrderHeader\n",
    "    \"\"\", import_conn)\n",
    "    \n",
    "    purchase_detail = pd.read_sql_query(\"\"\"\n",
    "        SELECT \n",
    "            PurchaseOrderID,\n",
    "            PurchaseOrderDetailID,\n",
    "            OrderQty,\n",
    "            ProductID,\n",
    "            UnitPrice,\n",
    "            LineTotal\n",
    "        FROM Purchasing_PurchaseOrderDetail\n",
    "    \"\"\", import_conn)\n",
    "   \n",
    "    purchase_merged = purchase_header.merge(purchase_detail, left_on='PurchaseID', right_on='PurchaseOrderID', how='inner')\n",
    " \n",
    "    purchase_merged['InventoryValue'] = purchase_merged['LineTotal'] * 1.1\n",
    "\n",
    "    final_df = purchase_merged[[\n",
    "        'PurchaseID',\n",
    "        'OrderDate',\n",
    "        'ProductID',\n",
    "        'EmployeeID',\n",
    "        'VendorID',\n",
    "        'OrderQty',\n",
    "        'UnitPrice',\n",
    "        'Freight',\n",
    "        'TaxAmt',\n",
    "        'TotalDue',\n",
    "        'LineTotal',\n",
    "        'InventoryValue'\n",
    "    ]].rename(columns={\n",
    "        'OrderDate': 'PurchaseDateID',\n",
    "        'OrderQty': 'OrderQuantity'\n",
    "    })\n",
    "    \n",
    "    # Voeg LocationID toe als NULL\n",
    "    final_df['LocationID'] = None\n",
    "    \n",
    "    existing_ids = pd.read_sql_query(\"SELECT PurchaseID FROM Fact_Purchase\", export_conn)['PurchaseID'].tolist()\n",
    " \n",
    "    new_purchases = final_df[~final_df['PurchaseID'].isin(existing_ids)]\n",
    "\n",
    "    cursor = export_conn.cursor()\n",
    "    success_count = 0\n",
    "    \n",
    "    for index, row in new_purchases.iterrows():\n",
    "        try:\n",
    "            query = '''\n",
    "                INSERT INTO Fact_Purchase \n",
    "                (PurchaseID, PurchaseDateID, ProductID, EmployeeID, LocationID, VendorID,\n",
    "                 OrderQuantity, UnitPrice, Freight, TaxAmt, TotalDue, \n",
    "                 LineTotal, InventoryValue) \n",
    "                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "            '''\n",
    "            values = (\n",
    "                row['PurchaseID'],\n",
    "                row['PurchaseDateID'],\n",
    "                row['ProductID'],\n",
    "                row['EmployeeID'],\n",
    "                None,  # LocationID\n",
    "                row['VendorID'],\n",
    "                row['OrderQuantity'],\n",
    "                row['UnitPrice'],\n",
    "                row['Freight'],\n",
    "                row['TaxAmt'],\n",
    "                row['TotalDue'],\n",
    "                row['LineTotal'],\n",
    "                row['InventoryValue']\n",
    "            )\n",
    "            cursor.execute(query, values)\n",
    "            success_count += 1\n",
    "        except Exception as e:\n",
    "            pass \n",
    "    \n",
    "    export_conn.commit()\n",
    "    print(f\"{success_count} nieuwe purchase records toegevoegd aan Fact_Purchase\")\n",
    "\n",
    "move_feitpurchase(import_conn, export_conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "750c848c",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_conn.close()\n",
    "import_conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
