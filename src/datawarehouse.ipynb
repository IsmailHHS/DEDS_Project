{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b8770c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "export_conn = pyodbc.connect(\n",
    "    'DRIVER={ODBC Driver 17 for SQL Server};'\n",
    "    'SERVER=(localdb)\\\\MSSQLLocalDB;'\n",
    "    'DATABASE=projectdatawarehouse;'\n",
    "    'Trusted_Connection=yes;'\n",
    ")\n",
    "\n",
    "export_cursor = export_conn.cursor()\n",
    "\n",
    "import_conn = pyodbc.connect(\n",
    "    'DRIVER={ODBC Driver 17 for SQL Server};'\n",
    "    'SERVER=(localdb)\\\\MSSQLLocalDB;'\n",
    "    'DATABASE=projectsourcedatamodel;'\n",
    "    'Trusted_Connection=yes;'\n",
    ")\n",
    "\n",
    "import_cursor = import_conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "309ac568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alle tabellen zijn geleegd.\n"
     ]
    }
   ],
   "source": [
    "def clear_tables():\n",
    "    tables = [\n",
    "        'Fact_EmployeePerformance',\n",
    "        'Fact_Sales',\n",
    "        'Fact_Purchase',\n",
    "        'Dim_Employee',\n",
    "        'Dim_Location',\n",
    "        'Dim_DateTime',\n",
    "        'Dim_Product',\n",
    "        'Dim_Vendor',\n",
    "        'Dim_Customer'\n",
    "    ]\n",
    "\n",
    "    for table in tables:\n",
    "        export_cursor.execute(f\"DELETE FROM {table}\")\n",
    "        export_conn.commit()\n",
    "\n",
    "    print(\"Alle tabellen zijn geleegd.\")\n",
    "\n",
    "clear_tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3a361800",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ibrah\\AppData\\Local\\Temp\\ipykernel_20572\\324957438.py:3: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  customer = pd.read_sql_query(\"SELECT CustomerID, Fname, Lname, Phone, Address, City, Region, State, Country FROM Customer\", import_conn)\n",
      "C:\\Users\\ibrah\\AppData\\Local\\Temp\\ipykernel_20572\\324957438.py:4: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  customer_customer_demo = pd.read_sql_query(\"SELECT CustomerID, CustomerTypeID FROM CustomerCustomerDemo\", import_conn)\n",
      "C:\\Users\\ibrah\\AppData\\Local\\Temp\\ipykernel_20572\\324957438.py:5: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  customer_demographics = pd.read_sql_query(\"SELECT CustomerTypeID, CustomerDesc FROM CustomerDemographics\", import_conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "217 customers verwerkt in Dim_Customer\n"
     ]
    }
   ],
   "source": [
    "def move_dimcustomer(import_conn, export_conn):\n",
    "    # Data ophalen uit de verschillende tabellen\n",
    "    customer = pd.read_sql_query(\"SELECT CustomerID, Fname, Lname, Phone, Address, City, Region, State, Country FROM Customer\", import_conn)\n",
    "    customer_customer_demo = pd.read_sql_query(\"SELECT CustomerID, CustomerTypeID FROM CustomerCustomerDemo\", import_conn)\n",
    "    customer_demographics = pd.read_sql_query(\"SELECT CustomerTypeID, CustomerDesc FROM CustomerDemographics\", import_conn)\n",
    "    \n",
    "    # Data mergen met pandas\n",
    "    merged_df = customer.merge(customer_customer_demo, on='CustomerID', how='left')\n",
    "    merged_df = merged_df.merge(customer_demographics, on='CustomerTypeID', how='left')\n",
    "    \n",
    "    # Kolommen transformeren\n",
    "    merged_df['FullName'] = merged_df['Fname'] + ' ' + merged_df['Lname']\n",
    "    merged_df['Region'] = merged_df['Region'].combine_first(merged_df['State'])  # Gebruik Region, fallback op State\n",
    "    \n",
    "    # Selecteer alleen de benodigde kolommen\n",
    "    final_df = merged_df[[\n",
    "        'CustomerID', \n",
    "        'FullName', \n",
    "        'CustomerDesc',  # Dit is de CustomerType die we willen\n",
    "        'Phone', \n",
    "        'Address', \n",
    "        'City', \n",
    "        'Region', \n",
    "        'Country'\n",
    "    ]].rename(columns={'CustomerDesc': 'CustomerType'})\n",
    "    \n",
    "    # Data naar doeltablet schrijven\n",
    "    cursor = export_conn.cursor()\n",
    "    \n",
    "    for index, row in final_df.iterrows():\n",
    "        try:\n",
    "            query = '''\n",
    "                INSERT INTO Dim_Customer \n",
    "                (CustomerID, FullName, CustomerType, PhoneNumber, Address, City, Region, Country) \n",
    "                SELECT ?, ?, ?, ?, ?, ?, ?, ?\n",
    "                WHERE NOT EXISTS (\n",
    "                    SELECT 1 FROM Dim_Customer WHERE CustomerID = ?\n",
    "                )\n",
    "            '''\n",
    "            cursor.execute(query, tuple(row.fillna('')) + (row['CustomerID'],))\n",
    "        except Exception as e:\n",
    "            print(f\"Fout bij invoegen customer {row['CustomerID']}: {e}\")\n",
    "    \n",
    "    export_conn.commit()\n",
    "    print(f\"{len(final_df)} customers verwerkt in Dim_Customer\")\n",
    "\n",
    "# Roep de functie aan\n",
    "move_dimcustomer(import_conn, export_conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9553e11e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351 employees imported into Dim_Employee\n"
     ]
    }
   ],
   "source": [
    "def move_dimemployee():\n",
    "    import_cursor.execute(\"\"\"\n",
    "        SELECT \n",
    "            e.EmployeeID,\n",
    "            e.FirstName + ' ' + e.LastName AS FullName,\n",
    "            COALESCE(e.JobTitle, e.Title, 'Onbekend') AS JobTitle,\n",
    "            d.dept_name AS Department,\n",
    "            e.HireDate,\n",
    "            e.BirthDate,\n",
    "            NULL AS EmailAddress,\n",
    "            NULL AS ManagerID  \n",
    "        FROM Employee e\n",
    "        LEFT JOIN Department d ON e.DepartmentID = d.dept_id\n",
    "    \"\"\")\n",
    "    \n",
    "    employees = import_cursor.fetchall()\n",
    "    \n",
    "    for employee in employees:\n",
    "        export_cursor.execute(\"\"\"\n",
    "            INSERT INTO Dim_Employee (\n",
    "                EmployeeID,\n",
    "                FullName,\n",
    "                JobTitle,\n",
    "                Department,\n",
    "                HireDate,\n",
    "                BirthDate,\n",
    "                EmailAddress,\n",
    "                ManagerID\n",
    "            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?)\n",
    "        \"\"\", employee)\n",
    "    \n",
    "    import_cursor.execute(\"\"\"\n",
    "        SELECT e.EmployeeID, e.manager_id\n",
    "        FROM Employee e\n",
    "        WHERE e.manager_id IS NOT NULL\n",
    "    \"\"\")\n",
    "    \n",
    "    manager_pairs = import_cursor.fetchall()\n",
    "    \n",
    "    for emp_id, manager_id in manager_pairs:\n",
    "        export_cursor.execute(\"\"\"\n",
    "            UPDATE Dim_Employee\n",
    "            SET ManagerID = ?\n",
    "            WHERE EmployeeID = ?\n",
    "            AND EXISTS (SELECT 1 FROM Dim_Employee WHERE EmployeeID = ?)  \n",
    "        \"\"\", (manager_id, emp_id, manager_id))\n",
    "    \n",
    "    export_conn.commit()\n",
    "    print(f\"{len(employees)} employees imported into Dim_Employee\")\n",
    "\n",
    "move_dimemployee()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "870ce7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ibrah\\AppData\\Local\\Temp\\ipykernel_20572\\2999684223.py:3: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  product = pd.read_sql_query(\"\"\"\n",
      "C:\\Users\\ibrah\\AppData\\Local\\Temp\\ipykernel_20572\\2999684223.py:16: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  category = pd.read_sql_query(\"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "585 products verwerkt in Dim_Product\n"
     ]
    }
   ],
   "source": [
    "def move_dimproduct(import_conn, export_conn):\n",
    "    # Data ophalen uit de verschillende tabellen\n",
    "    product = pd.read_sql_query(\"\"\"\n",
    "        SELECT \n",
    "            ProductID, \n",
    "            Name AS ProductName,\n",
    "            Color,\n",
    "            StandardCost,\n",
    "            ListPrice,\n",
    "            ProductLine,\n",
    "            Discontinued,\n",
    "            CategoryID\n",
    "        FROM Product\n",
    "    \"\"\", import_conn)\n",
    "    \n",
    "    category = pd.read_sql_query(\"\"\"\n",
    "        SELECT \n",
    "            CategoryID, \n",
    "            CategoryName AS ProductCategoryName\n",
    "        FROM Category\n",
    "    \"\"\", import_conn)\n",
    "    \n",
    "    # Data mergen met pandas\n",
    "    merged_df = product.merge(category, on='CategoryID', how='left')\n",
    "    \n",
    "    # Discontinued omzetten naar DiscontinuedDate (indien discontinued)\n",
    "    merged_df['DiscontinuedDate'] = merged_df['Discontinued'].apply(\n",
    "        lambda x: pd.Timestamp.today().date() if x == 1 else None\n",
    "    )\n",
    "    \n",
    "    # Selecteer alleen de benodigde kolommen\n",
    "    final_df = merged_df[[\n",
    "        'ProductID', \n",
    "        'ProductName', \n",
    "        'ProductCategoryName', \n",
    "        'Color', \n",
    "        'StandardCost', \n",
    "        'ListPrice', \n",
    "        'ProductLine', \n",
    "        'DiscontinuedDate'\n",
    "    ]]\n",
    "    \n",
    "    # Data naar doeltablet schrijven\n",
    "    cursor = export_conn.cursor()\n",
    "    \n",
    "    for index, row in final_df.iterrows():\n",
    "        try:\n",
    "            query = '''\n",
    "                INSERT INTO Dim_Product \n",
    "                (ProductID, ProductName, ProductCategoryName, Color, \n",
    "                 StandardCost, ListPrice, ProductLine, DiscontinuedDate) \n",
    "                SELECT ?, ?, ?, ?, ?, ?, ?, ?\n",
    "                WHERE NOT EXISTS (\n",
    "                    SELECT 1 FROM Dim_Product WHERE ProductID = ?\n",
    "                )\n",
    "            '''\n",
    "            # Tuple van waarden + ProductID voor de WHERE NOT EXISTS check\n",
    "            values = tuple(row.fillna('') if isinstance(row, pd.Series) else row) + (row['ProductID'],)\n",
    "            cursor.execute(query, values)\n",
    "        except Exception as e:\n",
    "            print(f\"Fout bij invoegen product {row['ProductID']}: {e}\")\n",
    "    \n",
    "    export_conn.commit()\n",
    "    print(f\"{len(final_df)} products verwerkt in Dim_Product\")\n",
    "\n",
    "# Roep de functie aan\n",
    "move_dimproduct(import_conn, export_conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f37b6b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ibrah\\AppData\\Local\\Temp\\ipykernel_20572\\923070079.py:5: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  customer = pd.read_sql_query(\"SELECT CustomerID, Address AS StreetAddress, City, State FROM Customer\", import_conn)\n",
      "C:\\Users\\ibrah\\AppData\\Local\\Temp\\ipykernel_20572\\923070079.py:6: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  state = pd.read_sql_query(\"SELECT State_id, State_name AS StateProvince, Country FROM State\", import_conn)\n",
      "C:\\Users\\ibrah\\AppData\\Local\\Temp\\ipykernel_20572\\923070079.py:7: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  order = pd.read_sql_query(\"SELECT OrderID, CustomerID, EmployeeID FROM [Order]\", import_conn)\n",
      "C:\\Users\\ibrah\\AppData\\Local\\Temp\\ipykernel_20572\\923070079.py:8: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  employee = pd.read_sql_query(\"SELECT EmployeeID, PostalCode FROM Employee\", import_conn)\n",
      "C:\\Users\\ibrah\\AppData\\Local\\Temp\\ipykernel_20572\\923070079.py:9: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  emp_terr = pd.read_sql_query(\"SELECT EmployeeID, TerritoryID FROM EmployeeTerritories\", import_conn)\n",
      "C:\\Users\\ibrah\\AppData\\Local\\Temp\\ipykernel_20572\\923070079.py:10: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  territories = pd.read_sql_query(\"SELECT TerritoryID, RegionID FROM Territories\", import_conn)\n",
      "C:\\Users\\ibrah\\AppData\\Local\\Temp\\ipykernel_20572\\923070079.py:11: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  region = pd.read_sql_query(\"SELECT RegionID, RegionDescription AS Region FROM Region\", import_conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "464 unieke locaties verwerkt in Dim_Location\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def move_dimlocation(import_conn, export_conn):\n",
    "    # Stap 1: Data ophalen uit de verschillende tabellen\n",
    "    customer = pd.read_sql_query(\"SELECT CustomerID, Address AS StreetAddress, City, State FROM Customer\", import_conn)\n",
    "    state = pd.read_sql_query(\"SELECT State_id, State_name AS StateProvince, Country FROM State\", import_conn)\n",
    "    order = pd.read_sql_query(\"SELECT OrderID, CustomerID, EmployeeID FROM [Order]\", import_conn)\n",
    "    employee = pd.read_sql_query(\"SELECT EmployeeID, PostalCode FROM Employee\", import_conn)\n",
    "    emp_terr = pd.read_sql_query(\"SELECT EmployeeID, TerritoryID FROM EmployeeTerritories\", import_conn)\n",
    "    territories = pd.read_sql_query(\"SELECT TerritoryID, RegionID FROM Territories\", import_conn)\n",
    "    region = pd.read_sql_query(\"SELECT RegionID, RegionDescription AS Region FROM Region\", import_conn)\n",
    "\n",
    "    # Stap 2: Merges uitvoeren\n",
    "    df = customer.merge(state, left_on='State', right_on='State_id', how='left') \\\n",
    "                 .merge(order, on='CustomerID', how='inner') \\\n",
    "                 .merge(employee, on='EmployeeID', how='inner') \\\n",
    "                 .merge(emp_terr, on='EmployeeID', how='inner') \\\n",
    "                 .merge(territories, on='TerritoryID', how='inner') \\\n",
    "                 .merge(region, on='RegionID', how='inner')\n",
    "\n",
    "    # Stap 3: Selecteer en hernoem benodigde kolommen\n",
    "    final_df = df[[\n",
    "        'StreetAddress', \n",
    "        'City', \n",
    "        'StateProvince', \n",
    "        'Region', \n",
    "        'Country', \n",
    "        'PostalCode'\n",
    "    ]].drop_duplicates()\n",
    "\n",
    "    # Stap 4: Data invoegen in Dim_Location\n",
    "    cursor = export_conn.cursor()\n",
    "\n",
    "    for index, row in final_df.iterrows():\n",
    "        try:\n",
    "            query = '''\n",
    "                INSERT INTO Dim_Location \n",
    "                (StreetAddress, City, StateProvince, Region, Country, PostalCode)\n",
    "                SELECT ?, ?, ?, ?, ?, ?\n",
    "                WHERE NOT EXISTS (\n",
    "                    SELECT 1 FROM Dim_Location \n",
    "                    WHERE StreetAddress = ? AND City = ? AND StateProvince = ? \n",
    "                          AND Region = ? AND Country = ? AND PostalCode = ?\n",
    "                )\n",
    "            '''\n",
    "            \n",
    "            values = tuple(\n",
    "                None if pd.isna(row[col]) else row[col]\n",
    "                for col in ['StreetAddress', 'City', 'StateProvince', 'Region', 'Country', 'PostalCode'] * 2\n",
    "            )\n",
    "            cursor.execute(query, values)\n",
    "        except Exception as e:\n",
    "            print(f\"Fout bij invoegen locatie (rij {index}): {e}\")\n",
    "\n",
    "    export_conn.commit()\n",
    "    print(f\"{len(final_df)} locaties verwerkt in Dim_Location\")\n",
    "\n",
    "# Roep de functie aan\n",
    "move_dimlocation(import_conn, export_conn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9802a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ibrah\\AppData\\Local\\Temp\\ipykernel_15888\\4020365802.py:3: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  header = pd.read_sql_query(\"\"\"\n",
      "C:\\Users\\ibrah\\AppData\\Local\\Temp\\ipykernel_15888\\4020365802.py:15: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  detail = pd.read_sql_query(\"\"\"\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'SalesOrderID'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_15888\\4020365802.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     74\u001b[39m \n\u001b[32m     75\u001b[39m     export_conn.commit()\n\u001b[32m     76\u001b[39m     print(f\"{len(final_df)} verkopen verwerkt in Fact_Sales\")\n\u001b[32m     77\u001b[39m \n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m move_feitsales(import_conn, export_conn)\n",
      "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_15888\\4020365802.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(import_conn, export_conn)\u001b[39m\n\u001b[32m     23\u001b[39m         FROM Sales_SalesOrderDetail\n\u001b[32m     24\u001b[39m     \"\"\", import_conn)\n\u001b[32m     25\u001b[39m \n\u001b[32m     26\u001b[39m     \u001b[38;5;66;03m# Stap 2: Merge header en detail via SalesOrderID\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m     merged_df = detail.merge(header, on=\u001b[33m'SalesOrderID'\u001b[39m, how=\u001b[33m'left'\u001b[39m)\n\u001b[32m     28\u001b[39m \n\u001b[32m     29\u001b[39m     \u001b[38;5;66;03m# Stap 3: Transformaties\u001b[39;00m\n\u001b[32m     30\u001b[39m     merged_df[\u001b[33m'DiscountAmount'\u001b[39m] = merged_df[\u001b[33m'UnitPrice'\u001b[39m] * merged_df[\u001b[33m'UnitPriceDiscount'\u001b[39m] * merged_df[\u001b[33m'Quantity'\u001b[39m]\n",
      "\u001b[32mc:\\Users\\ibrah\\Documents\\DEDS_Project\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[39m\n\u001b[32m  10828\u001b[39m         validate: MergeValidate | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m  10829\u001b[39m     ) -> DataFrame:\n\u001b[32m  10830\u001b[39m         \u001b[38;5;28;01mfrom\u001b[39;00m pandas.core.reshape.merge \u001b[38;5;28;01mimport\u001b[39;00m merge\n\u001b[32m  10831\u001b[39m \n\u001b[32m> \u001b[39m\u001b[32m10832\u001b[39m         return merge(\n\u001b[32m  10833\u001b[39m             self,\n\u001b[32m  10834\u001b[39m             right,\n\u001b[32m  10835\u001b[39m             how=how,\n",
      "\u001b[32mc:\\Users\\ibrah\\Documents\\DEDS_Project\\.venv\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[39m\n\u001b[32m    166\u001b[39m             validate=validate,\n\u001b[32m    167\u001b[39m             copy=copy,\n\u001b[32m    168\u001b[39m         )\n\u001b[32m    169\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m170\u001b[39m         op = _MergeOperation(\n\u001b[32m    171\u001b[39m             left_df,\n\u001b[32m    172\u001b[39m             right_df,\n\u001b[32m    173\u001b[39m             how=how,\n",
      "\u001b[32mc:\\Users\\ibrah\\Documents\\DEDS_Project\\.venv\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, indicator, validate)\u001b[39m\n\u001b[32m    790\u001b[39m             self.right_join_keys,\n\u001b[32m    791\u001b[39m             self.join_names,\n\u001b[32m    792\u001b[39m             left_drop,\n\u001b[32m    793\u001b[39m             right_drop,\n\u001b[32m--> \u001b[39m\u001b[32m794\u001b[39m         ) = self._get_merge_keys()\n\u001b[32m    795\u001b[39m \n\u001b[32m    796\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m left_drop:\n\u001b[32m    797\u001b[39m             self.left = self.left._drop_labels_or_levels(left_drop)\n",
      "\u001b[32mc:\\Users\\ibrah\\Documents\\DEDS_Project\\.venv\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1306\u001b[39m                     \u001b[38;5;28;01mif\u001b[39;00m lk \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1307\u001b[39m                         \u001b[38;5;66;03m# Then we're either Hashable or a wrong-length arraylike,\u001b[39;00m\n\u001b[32m   1308\u001b[39m                         \u001b[38;5;66;03m#  the latter of which will raise\u001b[39;00m\n\u001b[32m   1309\u001b[39m                         lk = cast(Hashable, lk)\n\u001b[32m-> \u001b[39m\u001b[32m1310\u001b[39m                         left_keys.append(left._get_label_or_level_values(lk))\n\u001b[32m   1311\u001b[39m                         join_names.append(lk)\n\u001b[32m   1312\u001b[39m                     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1313\u001b[39m                         \u001b[38;5;66;03m# work-around for merge_asof(left_index=True)\u001b[39;00m\n",
      "\u001b[32mc:\\Users\\ibrah\\Documents\\DEDS_Project\\.venv\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, key, axis)\u001b[39m\n\u001b[32m   1907\u001b[39m             values = self.xs(key, axis=other_axes[\u001b[32m0\u001b[39m])._values\n\u001b[32m   1908\u001b[39m         \u001b[38;5;28;01melif\u001b[39;00m self._is_level_reference(key, axis=axis):\n\u001b[32m   1909\u001b[39m             values = self.axes[axis].get_level_values(key)._values\n\u001b[32m   1910\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1911\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m KeyError(key)\n\u001b[32m   1912\u001b[39m \n\u001b[32m   1913\u001b[39m         \u001b[38;5;66;03m# Check for duplicates\u001b[39;00m\n\u001b[32m   1914\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m values.ndim > \u001b[32m1\u001b[39m:\n",
      "\u001b[31mKeyError\u001b[39m: 'SalesOrderID'"
     ]
    }
   ],
   "source": [
    "\n",
    "def move_feitsales(import_conn, export_conn):\n",
    "    # Stap 1: Data ophalen uit de bron\n",
    "    header = pd.read_sql_query(\"\"\"\n",
    "        SELECT \n",
    "            SalesOrderID,\n",
    "            OrderDate,\n",
    "            CustomerID,\n",
    "            NULL AS LocationID,\n",
    "            Freight,\n",
    "            TaxAmt,\n",
    "            TotalDue\n",
    "        FROM Sales_SalesOrderHeader\n",
    "    \"\"\", import_conn)\n",
    "\n",
    "    detail = pd.read_sql_query(\"\"\"\n",
    "        SELECT \n",
    "            SalesOrderID,\n",
    "            SalesOrderDetailID AS SalesID,\n",
    "            ProductID,\n",
    "            OrderQty AS Quantity,\n",
    "            UnitPrice,\n",
    "            UnitPriceDiscount,\n",
    "            LineTotal\n",
    "        FROM Sales_SalesOrderDetail\n",
    "    \"\"\", import_conn)\n",
    "\n",
    "    # Stap 2: Merge header en detail via SalesOrderID\n",
    "    merged_df = detail.merge(header, on='SalesOrderID', how='inner')\n",
    "\n",
    "    # Stap 3: Transformaties\n",
    "    merged_df['DiscountAmount'] = merged_df['UnitPrice'] * merged_df['UnitPriceDiscount'] * merged_df['Quantity']\n",
    "    merged_df['SalesAmount'] = merged_df['LineTotal'] - merged_df['DiscountAmount']\n",
    "    merged_df['Profit'] = merged_df['TotalDue'] - merged_df['LineTotal'] / merged_df['TotalDue'] \n",
    "\n",
    "    # (Optioneel) Genereer SaleDateID via datum-dimensie mapping\n",
    "    # Hier doen we gewoon een voorbeeld met jaarmaanddag als int\n",
    "    merged_df['SaleDateID'] = pd.to_datetime(merged_df['OrderDate']).dt.strftime('%Y%m%d').astype(int)\n",
    "\n",
    "    # Stap 4: Kolommen selecteren zoals in Fact_Sales\n",
    "    final_df = merged_df[[\n",
    "        'SalesID',\n",
    "        'SaleDateID',\n",
    "        'ProductID',\n",
    "        'CustomerID',\n",
    "        'LocationID',\n",
    "        'Quantity',\n",
    "        'UnitPrice',\n",
    "        'DiscountAmount',\n",
    "        'SalesAmount',\n",
    "        'TaxAmt',\n",
    "        'TotalDue',\n",
    "        'Profit'\n",
    "    ]]\n",
    "\n",
    "    # Stap 5: Data invoegen in Fact_Sales\n",
    "    cursor = export_conn.cursor()\n",
    "    for index, row in final_df.iterrows():\n",
    "        try:\n",
    "            query = '''\n",
    "                INSERT INTO Fact_Sales \n",
    "                (SalesID, SaleDateID, ProductID, CustomerID, LocationID,\n",
    "                 Quantity, UnitPrice, DiscountAmount, SalesAmount, TaxAmount, TotalAmount, Profit)\n",
    "                SELECT ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, \n",
    "                WHERE NOT EXISTS (\n",
    "                    SELECT 1 FROM Fact_Sales WHERE SalesID = ?\n",
    "                )\n",
    "            '''\n",
    "            values = tuple(\n",
    "                None if pd.isna(row[col]) else row[col]\n",
    "                for col in final_df.columns\n",
    "            ) + (row['SalesID'],)\n",
    "            cursor.execute(query, values)\n",
    "        except Exception as e:\n",
    "            print(f\"Fout bij invoegen verkoop (SalesID {row['SalesID']}): {e}\")\n",
    "\n",
    "    export_conn.commit()\n",
    "    print(f\"{len(final_df)} verkopen verwerkt in Fact_Sales\")\n",
    "\n",
    "move_feitsales(import_conn, export_conn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "750c848c",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_conn.close()\n",
    "import_conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
