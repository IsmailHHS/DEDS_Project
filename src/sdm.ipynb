{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "import sqlite3\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_conn = pyodbc.connect(\n",
    "    'DRIVER={ODBC Driver 17 for SQL Server};'\n",
    "    'SERVER=(localdb)\\\\MSSQLLocalDB;'\n",
    "    'DATABASE=projectsourcedatamodel;'\n",
    "    'Trusted_Connection=yes;'\n",
    ")\n",
    "\n",
    "export_cursor = export_conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alle tabellen zijn geleegd.\n"
     ]
    }
   ],
   "source": [
    "def clear_tables():\n",
    "    tables = [\"Purchasing_PurchaseOrderDetail\", \"Purchasing_PurchaseOrderHeader\", \"Purchasing_Vendor\", \"Sales_Order_Item\", \"Order_Details\", \"Bonus\", \"EmployeeTerritories\", \"[Order]\", \"Employee\", \"Production_BillOfMaterials\", \"Sales_SalesOrderDetail\", \"Production_Product\", \"Product\", \"Sales_SalesOrderHeader\", \"CustomerCustomerDemo\", \"Customer\", \"CustomerDemographics\", \"Sales_Customer\", \"Person_Address\", \"Sales_Store\", \"Person_Person\", \"Sales_SalesTerritory\", \"Territories\", \"State\", \"Region\", \"Category\", \"Suppliers\", \"Department\", \"Shippers\"]\n",
    "\n",
    "    for table in tables:\n",
    "        export_cursor.execute(f\"DELETE FROM {table}\")\n",
    "        export_conn.commit()\n",
    "\n",
    "\n",
    "    print(\"Alle tabellen zijn geleegd.\")\n",
    "\n",
    "clear_tables()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "nconn =  pyodbc.connect(\n",
    "    'DRIVER={ODBC Driver 17 for SQL Server};'\n",
    "    'SERVER=(localdb)\\\\MSSQLLocalDB;'\n",
    "    'DATABASE=Northwind;'\n",
    "    'Trusted_Connection=yes;'\n",
    ")\n",
    "\n",
    "nconn_cursor = nconn.cursor()\n",
    "\n",
    "aenconn = sqlite3.connect('c:/Users/ibrah/Documents/DEDS_Project/src/Data/Raw/aenc.sqlite')\n",
    "advconn = sqlite3.connect('c:/Users/ibrah/Documents/DEDS_Project/src/Data/Raw/adventureworks.sqlite')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ibrah\\AppData\\Local\\Temp\\ipykernel_9068\\3807513202.py:2: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql_query(\"SELECT * FROM Shippers\", nconn)\n"
     ]
    }
   ],
   "source": [
    "def move_shippers():\n",
    "    df = pd.read_sql_query(\"SELECT * FROM Shippers\", nconn)\n",
    "    for index, row in df.iterrows():\n",
    "        try:\n",
    "            query = f\"INSERT INTO Shippers VALUES ({row['ShipperID']}, '{row['CompanyName'].replace(\"'\", \"''\")}', '{row['Phone']}')\"\n",
    "            export_cursor.execute(query)\n",
    "        except pyodbc.Error as e:\n",
    "            print(f\"Fout in Shippers: {e}\")\n",
    "    export_conn.commit()\n",
    "move_shippers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_department():\n",
    "    aen_df = pd.read_sql_query(\"SELECT dept_id, dept_name, dept_head_id FROM Department\", aenconn)\n",
    "    adv_df = pd.read_sql_query(\"SELECT DepartmentID as dept_id, Name as dept_name, GroupName FROM HumanResources_Department\", advconn)\n",
    "    \n",
    "    combined_df = pd.concat([\n",
    "        aen_df[['dept_id', 'dept_name', 'dept_head_id']],\n",
    "        adv_df[['dept_id', 'dept_name', 'GroupName']].assign(dept_head_id=None) \n",
    "    ]).drop_duplicates('dept_id')  \n",
    "    \n",
    "    for index, row in combined_df.iterrows():\n",
    "        try:\n",
    "            query = f\"\"\"\n",
    "            INSERT INTO Department (\n",
    "                Dept_id,\n",
    "                Dept_name,\n",
    "                Dept_head_id,\n",
    "                GroupName,\n",
    "                ModifiedDate\n",
    "            ) VALUES (\n",
    "                {row['dept_id']},\n",
    "                '{row['dept_name'].replace(\"'\", \"''\") if pd.notna(row['dept_name']) else ''}',\n",
    "                {row['dept_head_id'] if pd.notna(row['dept_head_id']) else 'NULL'},\n",
    "                {f\"'{row['GroupName'].replace(\"'\", \"''\")}'\" if pd.notna(row['GroupName']) else 'NULL'},\n",
    "                {'NULL'}   \n",
    "            )\n",
    "            \"\"\"\n",
    "            export_cursor.execute(query)\n",
    "        except pyodbc.Error as e:\n",
    "            print(f\"Fout in Department insert (dept_id: {row['dept_id']}): {e}\")\n",
    "    \n",
    "    export_conn.commit()\n",
    "\n",
    "move_department()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ibrah\\AppData\\Local\\Temp\\ipykernel_9068\\1321044012.py:2: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql_query(\"SELECT * FROM Suppliers\", nconn)\n"
     ]
    }
   ],
   "source": [
    "def move_suppliers():\n",
    "    df = pd.read_sql_query(\"SELECT * FROM Suppliers\", nconn)\n",
    "    for index, row in df.iterrows():\n",
    "        try:\n",
    "            query = \"\"\"\n",
    "            INSERT INTO Suppliers (\n",
    "                SupplierID, CompanyName, ContactName, ContactTitle,\n",
    "                Address, City, Region, PostalCode, Country,\n",
    "                Phone, Fax, HomePage\n",
    "            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "            \"\"\"\n",
    "            export_cursor.execute(query,\n",
    "                row['SupplierID'],\n",
    "                row['CompanyName'],\n",
    "                row['ContactName'] if pd.notna(row['ContactName']) else None,\n",
    "                row['ContactTitle'] if pd.notna(row['ContactTitle']) else None,\n",
    "                row['Address'] if pd.notna(row['Address']) else None,\n",
    "                row['City'] if pd.notna(row['City']) else None,\n",
    "                row['Region'] if pd.notna(row['Region']) else None,\n",
    "                row['PostalCode'] if pd.notna(row['PostalCode']) else None,\n",
    "                row['Country'] if pd.notna(row['Country']) else None,\n",
    "                row['Phone'] if pd.notna(row['Phone']) else None,\n",
    "                row['Fax'] if pd.notna(row['Fax']) else None,\n",
    "                row['HomePage'] if pd.notna(row['HomePage']) else None\n",
    "            )\n",
    "        except pyodbc.Error as e:\n",
    "            print(f\"Fout in Suppliers (SupplierID: {row['SupplierID']}): {e}\")\n",
    "    export_conn.commit()\n",
    "\n",
    "move_suppliers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ibrah\\AppData\\Local\\Temp\\ipykernel_9068\\439097002.py:11: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  n_df = pd.read_sql_query(\"\"\"\n"
     ]
    }
   ],
   "source": [
    "def move_category():\n",
    "    adv_df = pd.read_sql_query(\"\"\"\n",
    "        SELECT \n",
    "            ProductCategoryID as CategoryID, \n",
    "            Name as CategoryName,\n",
    "            NULL as Description,\n",
    "            NULL as Picture\n",
    "        FROM Production_ProductCategory\n",
    "    \"\"\", advconn)\n",
    "\n",
    "    n_df = pd.read_sql_query(\"\"\"\n",
    "        SELECT \n",
    "            CategoryID,\n",
    "            CategoryName,\n",
    "            Description,\n",
    "            Picture\n",
    "        FROM Categories\n",
    "    \"\"\", nconn)\n",
    "    \n",
    "    combined_df = pd.concat([adv_df, n_df], ignore_index=True)\n",
    "    combined_df = combined_df.drop_duplicates(subset=['CategoryID'], keep='first')\n",
    "\n",
    "    for index, row in combined_df.iterrows():\n",
    "        try:\n",
    "            description = None if pd.isna(row['Description']) else row['Description']\n",
    "            \n",
    "            query = \"\"\"\n",
    "            INSERT INTO Category (\n",
    "                CategoryID,\n",
    "                CategoryName,\n",
    "                Description,\n",
    "                Picture,\n",
    "                rowguid,\n",
    "                ModifiedDate\n",
    "            ) VALUES (?, ?, ?, ?, NULL, NULL)\n",
    "            \"\"\"\n",
    "            export_cursor.execute(query, \n",
    "                row['CategoryID'],\n",
    "                row['CategoryName'],\n",
    "                description,\n",
    "                row['Picture'] if not pd.isna(row['Picture']) else None\n",
    "            )\n",
    "            \n",
    "        except pyodbc.Error as e:\n",
    "            print(f\"Fout in Category insert (CategoryID: {row['CategoryID']}): {e}\")\n",
    "    \n",
    "    export_conn.commit()\n",
    "move_category()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ibrah\\AppData\\Local\\Temp\\ipykernel_9068\\794136371.py:2: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql_query(\"SELECT * FROM Region\", nconn)\n"
     ]
    }
   ],
   "source": [
    "def move_region():\n",
    "    df = pd.read_sql_query(\"SELECT * FROM Region\", nconn)\n",
    "    for index, row in df.iterrows():\n",
    "        try:\n",
    "            query = f\"INSERT INTO Region VALUES ({row['RegionID']}, '{row['RegionDescription']}')\"\n",
    "            export_cursor.execute(query)\n",
    "        except pyodbc.Error as e:\n",
    "            print(f\"Fout in Region: {e}\")\n",
    "    export_conn.commit()\n",
    "move_region()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_state():\n",
    "    df = pd.read_sql_query(\"SELECT * FROM State\", aenconn)\n",
    "    for index, row in df.iterrows():\n",
    "        try:\n",
    "            query = f\"\"\"\n",
    "            INSERT INTO State VALUES (\n",
    "                '{row['state_id']}',\n",
    "                '{row['state_name'].replace(\"'\", \"''\")}',\n",
    "                '{row['state_capital'].replace(\"'\", \"''\")}',\n",
    "                '{row['country'].replace(\"'\", \"''\")}',\n",
    "                '{row['region'].replace(\"'\", \"''\")}'\n",
    "            )\n",
    "            \"\"\"\n",
    "            export_cursor.execute(query)\n",
    "        except pyodbc.Error as e:\n",
    "            print(f\"Fout in State: {e}\")\n",
    "    export_conn.commit()\n",
    "move_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ibrah\\AppData\\Local\\Temp\\ipykernel_9068\\1174576530.py:2: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql_query(\"SELECT * FROM Territories\", nconn)\n"
     ]
    }
   ],
   "source": [
    "def move_territories():\n",
    "    df = pd.read_sql_query(\"SELECT * FROM Territories\", nconn)\n",
    "    for index, row in df.iterrows():\n",
    "        try:\n",
    "            query = f\"\"\"\n",
    "            INSERT INTO Territories VALUES (\n",
    "                '{row['TerritoryID']}',\n",
    "                '{row['TerritoryDescription']}',\n",
    "                {row['RegionID']}\n",
    "            )\n",
    "            \"\"\"\n",
    "            export_cursor.execute(query)\n",
    "        except pyodbc.Error as e:\n",
    "            print(f\"Fout in Territories: {e}\")\n",
    "    export_conn.commit()\n",
    "move_territories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_sales_territory():\n",
    "    df = pd.read_sql_query(\"SELECT * FROM Sales_SalesTerritory\", advconn)\n",
    "    for index, row in df.iterrows():\n",
    "        try:\n",
    "            query = \"\"\"\n",
    "            INSERT INTO Sales_SalesTerritory (\n",
    "                TerritoryID, Name, CountryRegionCode, [Group],\n",
    "                SalesYTD, CostYTD, CostLastYear, rowguid, ModifiedDate\n",
    "            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "            \"\"\"\n",
    "            export_cursor.execute(query, \n",
    "                row['TerritoryID'],\n",
    "                row['Name'],\n",
    "                row['CountryRegionCode'],\n",
    "                row['Group'],\n",
    "                row['SalesYTD'],\n",
    "                row['CostYTD'],\n",
    "                row['CostLastYear'],\n",
    "                row['rowguid'],\n",
    "                row['ModifiedDate']\n",
    "            )\n",
    "        except pyodbc.Error as e:\n",
    "            print(f\"Fout in Sales_SalesTerritory (TerritoryID: {row['TerritoryID']}): {e}\")\n",
    "    export_conn.commit()\n",
    "    \n",
    "move_sales_territory()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_person_person():\n",
    "    df = pd.read_sql_query(\"SELECT * FROM Person_Person\", advconn)\n",
    "    for index, row in df.iterrows():\n",
    "        try:\n",
    "            query = \"\"\"\n",
    "            INSERT INTO Person_Person (\n",
    "                BusinessEntityID, PersonType, NameStyle, Title,\n",
    "                FirstName, MiddleName, LastName, Suffix,\n",
    "                EmailPromotion, rowguid, ModifiedDate\n",
    "            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "            \"\"\"\n",
    "            export_cursor.execute(query,\n",
    "                row['BusinessEntityID'],\n",
    "                row['PersonType'],\n",
    "                row['NameStyle'],\n",
    "                row['Title'],\n",
    "                row['FirstName'],\n",
    "                row['MiddleName'],\n",
    "                row['LastName'],\n",
    "                row['Suffix'],\n",
    "                row['EmailPromotion'],\n",
    "                row['rowguid'],\n",
    "                row['ModifiedDate']\n",
    "            )\n",
    "        except pyodbc.Error as e:\n",
    "            print(f\"Fout in Person_Person (BusinessEntityID: {row['BusinessEntityID']}): {e}\")\n",
    "    export_conn.commit()\n",
    "    \n",
    "move_person_person()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_sales_store():\n",
    "    df = pd.read_sql_query(\"SELECT * FROM Sales_Store\", advconn)\n",
    "    for index, row in df.iterrows():\n",
    "        try:\n",
    "            query = \"\"\"\n",
    "            INSERT INTO Sales_Store (\n",
    "                BusinessEntityID, Name, SalesPersonID, rowguid, ModifiedDate\n",
    "            ) VALUES (?, ?, ?, ?, ?)\n",
    "            \"\"\"\n",
    "            export_cursor.execute(query,\n",
    "                row['BusinessEntityID'],\n",
    "                row['Name'],\n",
    "                row['SalesPersonID'],\n",
    "                row['rowguid'],\n",
    "                row['ModifiedDate']\n",
    "            )\n",
    "        except pyodbc.Error as e:\n",
    "            print(f\"Fout in Sales_Store (BusinessEntityID: {row['BusinessEntityID']}): {e}\")\n",
    "    export_conn.commit()\n",
    "    \n",
    "move_sales_store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def move_person_address():\n",
    "    df = pd.read_sql_query(\"SELECT * FROM Person_Address\", advconn)\n",
    "    for index, row in df.iterrows():\n",
    "        try:\n",
    "            query = \"\"\"\n",
    "            INSERT INTO Person_Address (\n",
    "                AddressID, AddressLine1, City, StateProvinceID,\n",
    "                PostalCode, rowguid, ModifiedDate\n",
    "            ) VALUES (?, ?, ?, ?, ?, ?, ?)\n",
    "            \"\"\"\n",
    "            export_cursor.execute(query,\n",
    "                row['AddressID'],\n",
    "                row['AddressLine1'],\n",
    "                row['City'],\n",
    "                row['StateProvinceID'],\n",
    "                row['PostalCode'],\n",
    "                row['rowguid'],\n",
    "                row['ModifiedDate']\n",
    "            )\n",
    "        except pyodbc.Error as e:\n",
    "            print(f\"Fout in Person_Address (AddressID: {row['AddressID']}): {e}\")\n",
    "    export_conn.commit()\n",
    "    \n",
    "move_person_address()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_sales_customer():\n",
    "    df = pd.read_sql_query(\"\"\"\n",
    "        SELECT CustomerID, PersonID, StoreID, TerritoryID,\n",
    "               CAST(AccountNumber AS NVARCHAR(50)) AS AccountNumber,\n",
    "               rowguid, ModifiedDate\n",
    "        FROM Sales_Customer\n",
    "    \"\"\", advconn)\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        try:\n",
    "            export_cursor.execute(\"\"\"\n",
    "                INSERT INTO Sales_Customer VALUES (?, ?, ?, ?, ?, ?, ?)\n",
    "            \"\"\", \n",
    "            row['CustomerID'],\n",
    "            row['PersonID'] if pd.notna(row['PersonID']) else None,\n",
    "            row['StoreID'] if pd.notna(row['StoreID']) else None,\n",
    "            row['TerritoryID'] if pd.notna(row['TerritoryID']) else None,\n",
    "            str(row['AccountNumber']) if pd.notna(row['AccountNumber']) else None,\n",
    "            row['rowguid'],\n",
    "            row['ModifiedDate']\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Fout bij CustomerID {row['CustomerID']}: {str(e)[:100]}...\")\n",
    "\n",
    "    export_conn.commit()\n",
    "move_sales_customer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomerDemographics klaar: 0 rijen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ibrah\\AppData\\Local\\Temp\\ipykernel_9068\\3912574070.py:2: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql_query(\"SELECT * FROM CustomerDemographics\", nconn)\n"
     ]
    }
   ],
   "source": [
    "def move_customer_demographics():\n",
    "    df = pd.read_sql_query(\"SELECT * FROM CustomerDemographics\", nconn)\n",
    "    for _, row in df.iterrows():\n",
    "        try:\n",
    "            export_cursor.execute(\"INSERT INTO CustomerDemographics VALUES (?, ?)\", \n",
    "                               row['CustomerTypeID'], \n",
    "                               row['CustomerDesc'])\n",
    "        except Exception as e:\n",
    "            print(f\"Fout bij CustomerTypeID .\")\n",
    "    export_conn.commit()\n",
    "    print(f\"CustomerDemographics klaar: {len(df)} rijen\")\n",
    "move_customer_demographics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ibrah\\AppData\\Local\\Temp\\ipykernel_9068\\2187607761.py:3: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  n_df = pd.read_sql_query(\"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer migratie voltooid. 217 rijen toegevoegd.\n"
     ]
    }
   ],
   "source": [
    "def move_customer():\n",
    "    \n",
    "    n_df = pd.read_sql_query(\"\"\"\n",
    "        SELECT \n",
    "            CustomerID,\n",
    "            CompanyName,\n",
    "            ContactName,\n",
    "            ContactTitle,\n",
    "            Address,\n",
    "            City,\n",
    "            Region,\n",
    "            PostalCode,\n",
    "            Country,\n",
    "            Phone,\n",
    "            Fax,\n",
    "            NULL AS Fname,\n",
    "            NULL AS Lname,\n",
    "            NULL AS State\n",
    "        FROM Customers\n",
    "    \"\"\", nconn)\n",
    "    \n",
    "    aen_df = pd.read_sql_query(\"\"\"\n",
    "        SELECT \n",
    "            id AS CustomerID,\n",
    "            company_name AS CompanyName,\n",
    "            NULL AS ContactName,\n",
    "            NULL AS ContactTitle,\n",
    "            address AS Address,\n",
    "            city AS City,\n",
    "            NULL AS Region,\n",
    "            zip AS PostalCode,\n",
    "            NULL AS Country,\n",
    "            phone AS Phone,\n",
    "            NULL AS Fax,\n",
    "            fname AS Fname,\n",
    "            lname AS Lname,\n",
    "            state AS State\n",
    "        FROM Customer\n",
    "    \"\"\", aenconn)\n",
    "    \n",
    "    combined_df = pd.concat([n_df, aen_df], ignore_index=True)\n",
    "\n",
    "    for _, row in combined_df.iterrows():\n",
    "        try:\n",
    "            export_cursor.execute(\"\"\"\n",
    "                INSERT INTO Customer (\n",
    "                    CustomerID, CompanyName, ContactName, ContactTitle,\n",
    "                    Address, City, Region, PostalCode, Country,\n",
    "                    Phone, Fax, Fname, Lname, State\n",
    "                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "            \"\"\", \n",
    "                row['CustomerID'],\n",
    "                row['CompanyName'],\n",
    "                row['ContactName'] if pd.notna(row['ContactName']) else None,\n",
    "                row['ContactTitle'] if pd.notna(row['ContactTitle']) else None,\n",
    "                row['Address'] if pd.notna(row['Address']) else None,\n",
    "                row['City'] if pd.notna(row['City']) else None,\n",
    "                row['Region'] if pd.notna(row['Region']) else None,\n",
    "                row['PostalCode'] if pd.notna(row['PostalCode']) else None,\n",
    "                row['Country'] if pd.notna(row['Country']) else None,\n",
    "                row['Phone'] if pd.notna(row['Phone']) else None,\n",
    "                row['Fax'] if pd.notna(row['Fax']) else None,\n",
    "                row['Fname'] if pd.notna(row['Fname']) else None,\n",
    "                row['Lname'] if pd.notna(row['Lname']) else None,\n",
    "                row['State'] if pd.notna(row['State']) else None\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Fout bij CustomerID {row['CustomerID']}: {str(e)[:100]}...\")\n",
    "    \n",
    "    export_conn.commit()\n",
    "    print(f\"Customer migratie voltooid. {len(combined_df)} rijen toegevoegd.\")\n",
    "\n",
    "move_customer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ibrah\\AppData\\Local\\Temp\\ipykernel_9068\\4134974665.py:2: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql_query(\"SELECT * FROM CustomerCustomerDemo\", nconn)\n"
     ]
    }
   ],
   "source": [
    "def move_customer_customer_demo():\n",
    "    df = pd.read_sql_query(\"SELECT * FROM CustomerCustomerDemo\", nconn)\n",
    "    for _, row in df.iterrows():\n",
    "        try:\n",
    "            export_cursor.execute(\"INSERT INTO CustomerCustomerDemo VALUES (?, ?)\", \n",
    "                               row['CustomerID'], \n",
    "                               row['CustomerTypeID'])\n",
    "        except Exception as e:\n",
    "            print(f\"Fout bij combinatie {row['CustomerID']}-{row['CustomerTypeID']}: {str(e)[:100]}...\")\n",
    "    export_conn.commit()\n",
    "\n",
    "move_customer_customer_demo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_sales_order_header():\n",
    "    df = pd.read_sql_query(\"\"\"\n",
    "        SELECT \n",
    "            SalesOrderID, RevisionNumber, OrderDate, DueDate, ShipDate,\n",
    "            Status, OnlineOrderFlag, SalesOrderNumber, PurchaseOrderNumber,\n",
    "            AccountNumber, CustomerID, SalesPersonID, TerritoryID,\n",
    "            BillToAddressID, ShipToAddressID, ShipMethodID, CreditCardID,\n",
    "            CreditCardApprovalCode, CurrencyRateID, SubTotal, TaxAmt,\n",
    "            Freight, TotalDue, Comment, rowguid, ModifiedDate\n",
    "        FROM Sales_SalesOrderHeader\n",
    "    \"\"\", advconn)  \n",
    "    success_count = 0\n",
    "    for _, row in df.iterrows():\n",
    "        try:\n",
    "            query = \"\"\"\n",
    "            INSERT INTO Sales_SalesOrderHeader (\n",
    "                SalesOrderID, RevisionNumber, OrderDate, DueDate, ShipDate,\n",
    "                Status, OnlineOrderFlag, SalesOrderNumber, PurchaseOrderNumber,\n",
    "                AccountNumber, CustomerID, SalesPersonID, TerritoryID,\n",
    "                BillToAddressID, ShipToAddressID, ShipMethodID, CreditCardID,\n",
    "                CreditCardApprovalCode, CurrencyRateID, SubTotal, TaxAmt,\n",
    "                Freight, TotalDue, Comment, rowguid, ModifiedDate\n",
    "            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "            \"\"\"\n",
    "            \n",
    "            params = (\n",
    "                row['SalesOrderID'],\n",
    "                row['RevisionNumber'],\n",
    "                row['OrderDate'] if pd.notna(row['OrderDate']) else None,\n",
    "                row['DueDate'] if pd.notna(row['DueDate']) else None,\n",
    "                row['ShipDate'] if pd.notna(row['ShipDate']) else None,\n",
    "                row['Status'],\n",
    "                row['OnlineOrderFlag'],\n",
    "                row['SalesOrderNumber'] if pd.notna(row['SalesOrderNumber']) else None,\n",
    "                row['PurchaseOrderNumber'] if pd.notna(row['PurchaseOrderNumber']) else None,\n",
    "                row['AccountNumber'] if pd.notna(row['AccountNumber']) else None,\n",
    "                row['CustomerID'] if pd.notna(row['CustomerID']) else None,\n",
    "                row['SalesPersonID'] if pd.notna(row['SalesPersonID']) else None,\n",
    "                row['TerritoryID'] if pd.notna(row['TerritoryID']) else None,\n",
    "                row['BillToAddressID'] if pd.notna(row['BillToAddressID']) else None,\n",
    "                row['ShipToAddressID'] if pd.notna(row['ShipToAddressID']) else None,\n",
    "                row['ShipMethodID'] if pd.notna(row['ShipMethodID']) else None,\n",
    "                row['CreditCardID'] if pd.notna(row['CreditCardID']) else None,\n",
    "                row['CreditCardApprovalCode'] if pd.notna(row['CreditCardApprovalCode']) else None,\n",
    "                row['CurrencyRateID'] if pd.notna(row['CurrencyRateID']) else None,\n",
    "                float(row['SubTotal']) if pd.notna(row['SubTotal']) else 0.0,\n",
    "                float(row['TaxAmt']) if pd.notna(row['TaxAmt']) else 0.0,\n",
    "                float(row['Freight']) if pd.notna(row['Freight']) else 0.0,\n",
    "                float(row['TotalDue']) if pd.notna(row['TotalDue']) else 0.0,\n",
    "                row['Comment'] if pd.notna(row['Comment']) else None,\n",
    "                row['rowguid'],\n",
    "                row['ModifiedDate'] if pd.notna(row['ModifiedDate']) else None\n",
    "            )\n",
    "            \n",
    "            export_cursor.execute(query, params)\n",
    "            success_count += 1\n",
    "            \n",
    "        except pyodbc.Error as e:\n",
    "            print(f\"Fout bij SalesOrderID {row['SalesOrderID']}: {str(e)[:200]}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Onverwachte fout bij SalesOrderID {row['SalesOrderID']}: {str(e)[:200]}\")\n",
    "    \n",
    "    export_conn.commit()\n",
    "    \n",
    "move_sales_order_header()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ibrah\\AppData\\Local\\Temp\\ipykernel_9068\\1782744661.py:23: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  n_df = pd.read_sql_query(\"\"\"\n"
     ]
    }
   ],
   "source": [
    "def move_product():\n",
    "    aen_df = pd.read_sql_query(\"\"\"\n",
    "        SELECT \n",
    "            id AS ProductID,\n",
    "            name AS Name,\n",
    "            description AS Description,\n",
    "            prod_size AS Prod_size,\n",
    "            color AS Color,\n",
    "            quantity AS Quantity,\n",
    "            unit_price AS UnitPrice,\n",
    "            picture_name AS Picture_name,\n",
    "            Category AS Category,\n",
    "            NULL AS SupplierID,\n",
    "            NULL AS CategoryID,\n",
    "            NULL AS QuantityPerUnit,\n",
    "            NULL AS UnitsInStock,\n",
    "            NULL AS UnitsOnOrder,\n",
    "            NULL AS ReorderLevel,\n",
    "            0 AS Discontinued\n",
    "        FROM Product\n",
    "    \"\"\", aenconn)\n",
    "\n",
    "    n_df = pd.read_sql_query(\"\"\"\n",
    "        SELECT \n",
    "            ProductID,\n",
    "            ProductName AS Name,\n",
    "            NULL AS Description,\n",
    "            NULL AS Prod_size,\n",
    "            NULL AS Color,\n",
    "            NULL AS Quantity,\n",
    "            UnitPrice,\n",
    "            NULL AS Picture_name,\n",
    "            NULL AS Category,\n",
    "            SupplierID,\n",
    "            CategoryID,\n",
    "            QuantityPerUnit,\n",
    "            UnitsInStock,\n",
    "            UnitsOnOrder,\n",
    "            ReorderLevel,\n",
    "            Discontinued\n",
    "        FROM Products\n",
    "    \"\"\", nconn)\n",
    "\n",
    "    combined_df = pd.concat([aen_df, n_df], ignore_index=True)\n",
    "\n",
    "    for _, row in combined_df.iterrows():\n",
    "        try:\n",
    "            query = \"\"\"\n",
    "            INSERT INTO Product (\n",
    "                ProductID, Name, Description, Prod_size, Color,\n",
    "                Quantity, unit_price, Picture_name, Category,\n",
    "                SupplierID, CategoryID, QuantityPerUnit,\n",
    "                UnitsInStock, UnitsOnOrder, ReorderLevel, Discontinued\n",
    "            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?,?)\n",
    "            \"\"\"\n",
    "            params = (\n",
    "                row['ProductID'],\n",
    "                (row['Name']), \n",
    "                (row['Description']) if pd.notna(row['Description']) else None,\n",
    "                (row['Prod_size']) if pd.notna(row['Prod_size']) else None,\n",
    "                (row['Color']) if pd.notna(row['Color']) else None,\n",
    "                (row['Quantity']) if pd.notna(row['Quantity']) else None,\n",
    "                (row['UnitPrice']) if pd.notna(row['UnitPrice']) else 0.0,\n",
    "                (row['Picture_name']) if pd.notna(row['Picture_name']) else None,\n",
    "                (row['Category']) if pd.notna(row['Category']) else None,\n",
    "                (row['SupplierID']) if pd.notna(row['SupplierID']) else None,\n",
    "                (row['CategoryID']) if pd.notna(row['CategoryID']) else None,\n",
    "                (row['QuantityPerUnit']) if pd.notna(row['QuantityPerUnit']) else None,\n",
    "                (row['UnitsInStock']) if pd.notna(row['UnitsInStock']) else None,\n",
    "                (row['UnitsOnOrder']) if pd.notna(row['UnitsOnOrder']) else None,\n",
    "                (row['ReorderLevel']) if pd.notna(row['ReorderLevel']) else None,\n",
    "                (row['Discontinued'])\n",
    "            )\n",
    "            export_cursor.execute(query, params)\n",
    "        except pyodbc.Error as e:\n",
    "            print(f\"Fout in Product (ProductID: {row['ProductID']}): {e}\")\n",
    "    \n",
    "    export_conn.commit()\n",
    "\n",
    "move_product()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_production_product():\n",
    "    df = pd.read_sql_query(\"SELECT * FROM Production_Product\", advconn)\n",
    "    \n",
    "    date_cols = ['SellStartDate', 'SellEndDate', 'ModifiedDate']\n",
    "    for col in date_cols:\n",
    "        df[col] = pd.to_datetime(df[col])\n",
    "    if 'rowguid' in df.columns:\n",
    "        df['rowguid'] = df['rowguid'].astype(str)\n",
    "    \n",
    "    if 'DiscontinuedDate' in df.columns:\n",
    "        df['DiscontinuedDate'] = pd.to_datetime(df['DiscontinuedDate']).dt.strftime('%Y-%m-%d')\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        try:\n",
    "            export_cursor.execute(\"\"\"\n",
    "                INSERT INTO Production_Product (\n",
    "                    ProductID, Name, ProductNumber, MakeFlag, FinishedGoodsFlag,\n",
    "                    Color, SafetyStockLevel, ReorderPoint, StandardCost, ListPrice,\n",
    "                    Size, SizeUnitMeasureCode, WeightUnitMeasureCode, Weight,\n",
    "                    DaysToManufacture, ProductLine, Class, Style, ProductSubcategoryID,\n",
    "                    ProductModelID, SellStartDate, SellEndDate, DiscontinuedDate,\n",
    "                    rowguid, ModifiedDate, ProductCategoryID\n",
    "                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "            \"\"\", \n",
    "                row['ProductID'],\n",
    "                row['Name'],\n",
    "                row['ProductNumber'],\n",
    "                row['MakeFlag'],\n",
    "                row['FinishedGoodsFlag'],\n",
    "                row['Color'] if pd.notnull(row['Color']) else None,\n",
    "                row['SafetyStockLevel'],\n",
    "                row['ReorderPoint'],\n",
    "                row['StandardCost'],\n",
    "                row['ListPrice'],\n",
    "                row['Size'] if pd.notnull(row['Size']) else None,\n",
    "                row['SizeUnitMeasureCode'] if pd.notnull(row['SizeUnitMeasureCode']) else None,\n",
    "                row['WeightUnitMeasureCode'] if pd.notnull(row['WeightUnitMeasureCode']) else None,\n",
    "                row['Weight'] if pd.notnull(row['Weight']) else None,\n",
    "                row['DaysToManufacture'],\n",
    "                row['ProductLine'] if pd.notnull(row['ProductLine']) else None,\n",
    "                row['Class'] if pd.notnull(row['Class']) else None,\n",
    "                row['Style'] if pd.notnull(row['Style']) else None,\n",
    "                row['ProductSubcategoryID'] if pd.notnull(row['ProductSubcategoryID']) else None,\n",
    "                row['ProductModelID'] if pd.notnull(row['ProductModelID']) else None,\n",
    "                row['SellStartDate'],\n",
    "                row['SellEndDate'] if pd.notnull(row['SellEndDate']) else None,\n",
    "                row['DiscontinuedDate'] if pd.notnull(row['DiscontinuedDate']) else None,\n",
    "                row['rowguid'],\n",
    "                row['ModifiedDate'],\n",
    "                row['ProductCategoryID'] if pd.notnull(row['ProductCategoryID']) else None\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Error with ProductID {row['ProductID']}: {str(e)}\")\n",
    "            print(f\"Problematic row values: {row.to_dict()}\")\n",
    "    \n",
    "    export_conn.commit()\n",
    "    \n",
    "move_production_product()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_sales_order_detail():\n",
    "    df = pd.read_sql_query(\"SELECT * FROM Sales_SalesOrderDetail\", advconn)\n",
    "    for index, row in df.iterrows():\n",
    "        try:\n",
    "            query = \"\"\"\n",
    "            INSERT INTO Sales_SalesOrderDetail (\n",
    "                SalesOrderDetailID, SalesOrderID, CarrierTrackingNumber, OrderQty,\n",
    "                ProductID, SpecialOfferID, UnitPrice, UnitPriceDiscount,\n",
    "                LineTotal, ModifiedDate\n",
    "            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "            \"\"\"\n",
    "            export_cursor.execute(query,\n",
    "                row['SalesOrderDetailID'],\n",
    "                row['SalesOrderID'],\n",
    "                row['CarrierTrackingNumber'],\n",
    "                row['OrderQty'],\n",
    "                row['ProductID'],\n",
    "                row['SpecialOfferID'],\n",
    "                row['UnitPrice'],\n",
    "                row['UnitPriceDiscount'],\n",
    "                row['LineTotal'],\n",
    "                row['ModifiedDate']\n",
    "            )\n",
    "        except pyodbc.Error as e:\n",
    "            print(f\"Fout in Sales_SalesOrderDetail (SalesOrderDetailID: {row['SalesOrderDetailID']}): {e}\")\n",
    "    export_conn.commit()\n",
    "move_sales_order_detail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ibrah\\AppData\\Local\\Temp\\ipykernel_9068\\3250266924.py:2: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  product_ids = pd.read_sql_query(\"SELECT ProductID FROM Production_Product\", export_conn)['ProductID'].tolist()\n"
     ]
    }
   ],
   "source": [
    "def move_bill_of_materials():\n",
    "    product_ids = pd.read_sql_query(\"SELECT ProductID FROM Production_Product\", export_conn)['ProductID'].tolist()\n",
    "    \n",
    "    df = pd.read_sql_query(\"SELECT * FROM Production_BillOfMaterials\", advconn)\n",
    "    \n",
    "    \n",
    "    df['StartDate'] = pd.to_datetime(df['StartDate']).dt.date\n",
    "    df['EndDate'] = pd.to_datetime(df['EndDate'], errors='coerce').dt.date\n",
    "    df['ModifiedDate'] = pd.to_datetime(df['ModifiedDate'])\n",
    "    \n",
    "    df['ProductAssemblyID'] = df['ProductAssemblyID'].where(\n",
    "        df['ProductAssemblyID'].isin(product_ids), None)\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        try:\n",
    "            query = \"\"\"\n",
    "            INSERT INTO Production_BillOfMaterials (\n",
    "                BillOfMaterialsID, ProductAssemblyID, ComponentID, StartDate,\n",
    "                EndDate, UnitMeasureCode, BOMLevel, PerAssemblyQty, ModifiedDate\n",
    "            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "            \"\"\"\n",
    "            params = (\n",
    "                int(row['BillOfMaterialsID']),\n",
    "                int(row['ProductAssemblyID']) if pd.notnull(row['ProductAssemblyID']) else None,\n",
    "                int(row['ComponentID']),\n",
    "                row['StartDate'],\n",
    "                row['EndDate'] if pd.notnull(row['EndDate']) else None,\n",
    "                str(row['UnitMeasureCode']).strip(),\n",
    "                int(row['BOMLevel']),\n",
    "                float(row['PerAssemblyQty']),\n",
    "                row['ModifiedDate']\n",
    "            )\n",
    "            \n",
    "            export_cursor.execute(query, params)\n",
    "            \n",
    "        except pyodbc.Error as e:\n",
    "            print(f\"\\nFout in rij {index} (BillOfMaterialsID: {row['BillOfMaterialsID']}): {e}\")\n",
    "    \n",
    "    export_conn.commit()\n",
    "\n",
    "move_bill_of_materials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ibrah\\AppData\\Local\\Temp\\ipykernel_9068\\3272414051.py:2: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  n_df = pd.read_sql_query(\"\"\"\n",
      "C:\\Users\\ibrah\\AppData\\Local\\Temp\\ipykernel_9068\\3272414051.py:46: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_df = pd.concat([n_df, aen_df, adv_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Foreign key constraint tijdelijk uitgeschakeld\n",
      "Eerste insert ronde voltooid. 351 rijen toegevoegd.\n",
      "Manager relaties bijgewerkt.\n",
      "Foreign key constraint weer ingeschakeld\n",
      "Kon foreign key constraint niet inschakelen: No results.  Previous SQL was not a query.\n"
     ]
    }
   ],
   "source": [
    "def move_employee():\n",
    "    n_df = pd.read_sql_query(\"\"\"\n",
    "        SELECT \n",
    "            EmployeeID, LastName, FirstName, Title, TitleOfCourtesy,\n",
    "            BirthDate, HireDate, Address, City, Region, PostalCode,\n",
    "            Country, HomePhone AS Phone, Extension, Photo, Notes,\n",
    "            ReportsTo AS manager_id, PhotoPath,\n",
    "            NULL AS dept_id, NULL AS street, NULL AS state, NULL AS zip_code,\n",
    "            NULL AS status, NULL AS ss_number, NULL AS salary, NULL AS start_date,\n",
    "            NULL AS Bene_health_ins, NULL AS Bene_life_ins, NULL AS Bene_day_care, NULL AS sex,\n",
    "            NULL AS NationalIDNumber, NULL AS LoginID, NULL AS OrganizationNode, NULL AS OrganizationLevel,\n",
    "            NULL AS JobTitle, NULL AS MaritalStatus, NULL AS Gender, NULL AS SalariedFlag,\n",
    "            NULL AS VacationHours, NULL AS SickLeaveHours, NULL AS CurrentFlag, NULL AS DepartmentID, NULL AS ModifiedDate\n",
    "        FROM dbo.Employees\n",
    "    \"\"\", nconn)\n",
    "    \n",
    "    aen_df = pd.read_sql_query(\"\"\"\n",
    "        SELECT \n",
    "            emp_id AS EmployeeID, emp_lname AS LastName, emp_fname AS FirstName,\n",
    "            NULL AS Title, NULL AS TitleOfCourtesy, birth_date AS BirthDate, start_date AS HireDate,\n",
    "            street AS Address, city AS City, state AS Region, zip_code AS PostalCode,\n",
    "            NULL AS Country, phone AS Phone, NULL AS Extension, NULL AS Photo, NULL AS Notes,\n",
    "            manager_id, dept_id, street, state, zip_code, status, ss_number, salary, start_date,\n",
    "            bene_health_ins AS Bene_health_ins, bene_life_ins AS Bene_life_ins, bene_day_care AS Bene_day_care, sex,\n",
    "            NULL AS NationalIDNumber, NULL AS LoginID, NULL AS OrganizationNode, NULL AS OrganizationLevel,\n",
    "            NULL AS JobTitle, NULL AS MaritalStatus, sex AS Gender, NULL AS SalariedFlag,\n",
    "            NULL AS VacationHours, NULL AS SickLeaveHours, NULL AS CurrentFlag, dept_id AS DepartmentID, NULL AS ModifiedDate, NULL AS PhotoPath\n",
    "        FROM Employee\n",
    "    \"\"\", aenconn)\n",
    "    \n",
    "    adv_df = pd.read_sql_query(\"\"\"\n",
    "        SELECT \n",
    "            BusinessEntityID AS EmployeeID, NULL AS LastName, NULL AS FirstName,\n",
    "            JobTitle AS Title, NULL AS TitleOfCourtesy, BirthDate, HireDate,\n",
    "            NULL AS Address, NULL AS City, NULL AS Region, NULL AS PostalCode,\n",
    "            NULL AS Country, NULL AS Phone, NULL AS Extension, NULL AS Photo, NULL AS Notes,\n",
    "            NULL AS manager_id, NULL AS dept_id, NULL AS street, NULL AS state, NULL AS zip_code,\n",
    "            NULL AS status, NULL AS ss_number, NULL AS salary, NULL AS start_date,\n",
    "            NULL AS Bene_health_ins, NULL AS Bene_life_ins, NULL AS Bene_day_care, NULL AS sex,\n",
    "            NationalIDNumber, LoginID, OrganizationNode, OrganizationLevel,\n",
    "            JobTitle, MaritalStatus, Gender, SalariedFlag,\n",
    "            VacationHours, SickLeaveHours, CurrentFlag, DepartmentID, ModifiedDate, NULL AS PhotoPath\n",
    "        FROM HumanResources_Employee\n",
    "    \"\"\", advconn)\n",
    "    \n",
    "    combined_df = pd.concat([n_df, aen_df, adv_df], ignore_index=True)\n",
    "    final_df = combined_df.groupby('EmployeeID', as_index=False).first()\n",
    "    \n",
    "    all_employee_ids = set(final_df['EmployeeID'])\n",
    "   \n",
    "    try:\n",
    "        export_cursor.execute(\"ALTER TABLE Employee NOCHECK CONSTRAINT FK__Employee__manage__5BE2A6F2\")\n",
    "        export_conn.commit()\n",
    "        print(\"Foreign key constraint tijdelijk uitgeschakeld\")\n",
    "    except Exception as e:\n",
    "        print(f\"Kon foreign key constraint niet uitschakelen: {str(e)}\")\n",
    "\n",
    "    for _, row in final_df.iterrows():\n",
    "        try:\n",
    "            start_date = str(row['start_date']) if pd.notna(row['start_date']) else None\n",
    "            \n",
    "            export_cursor.execute(\"\"\"\n",
    "                INSERT INTO Employee (\n",
    "                    EmployeeID, LastName, FirstName, Title, TitleOfCourtesy,\n",
    "                    BirthDate, HireDate, Address, City, Region, PostalCode,\n",
    "                    Country, Phone, Extension, Photo, Notes, PhotoPath,\n",
    "                    manager_id, dept_id, street, state, [zip-code], status,\n",
    "                    [ss-number], salary, start_date, Bene_health_ins, Bene_life_ins,\n",
    "                    Bene_day_care, sex, NationalIDNumber, LoginID, OrganizationNode,\n",
    "                    OrganizationLevel, JobTitle, MaritalStatus, Gender, SalariedFlag,\n",
    "                    VacationHours, SickLeaveHours, CurrentFlag, DepartmentID, ModifiedDate\n",
    "                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, \n",
    "                          ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "            \"\"\", \n",
    "                row['EmployeeID'],\n",
    "                row['LastName'] if pd.notna(row['LastName']) else None,\n",
    "                row['FirstName'] if pd.notna(row['FirstName']) else None,\n",
    "                row['Title'] if pd.notna(row['Title']) else None,\n",
    "                row['TitleOfCourtesy'] if pd.notna(row['TitleOfCourtesy']) else None,\n",
    "                row['BirthDate'] if pd.notna(row['BirthDate']) else None,\n",
    "                row['HireDate'] if pd.notna(row['HireDate']) else None,\n",
    "                row['Address'] if pd.notna(row['Address']) else None,\n",
    "                row['City'] if pd.notna(row['City']) else None,\n",
    "                row['Region'] if pd.notna(row['Region']) else None,\n",
    "                row['PostalCode'] if pd.notna(row['PostalCode']) else None,\n",
    "                row['Country'] if pd.notna(row['Country']) else None,\n",
    "                row['Phone'] if pd.notna(row['Phone']) else None,\n",
    "                row['Extension'] if pd.notna(row['Extension']) else None,\n",
    "                row['Photo'] if pd.notna(row['Photo']) else None,\n",
    "                row['Notes'] if pd.notna(row['Notes']) else None,\n",
    "                row['PhotoPath'] if pd.notna(row['PhotoPath']) else None,\n",
    "                None,  # Manager_id eerst op NULL zetten\n",
    "                row['dept_id'] if pd.notna(row['dept_id']) else None,\n",
    "                str(row['street']) if pd.notna(row['street']) else None,\n",
    "                str(row['state']) if pd.notna(row['state']) else None,\n",
    "                str(row['zip_code']) if pd.notna(row['zip_code']) else None,\n",
    "                str(row['status']) if pd.notna(row['status']) else None,\n",
    "                row['ss_number'] if pd.notna(row['ss_number']) else None,\n",
    "                float(row['salary']) if pd.notna(row['salary']) else None,\n",
    "                start_date,\n",
    "                str(row['Bene_health_ins']) if pd.notna(row['Bene_health_ins']) else None,\n",
    "                str(row['Bene_life_ins']) if pd.notna(row['Bene_life_ins']) else None,\n",
    "                str(row['Bene_day_care']) if pd.notna(row['Bene_day_care']) else None,\n",
    "                str(row['sex']) if pd.notna(row['sex']) else None,\n",
    "                str(row['NationalIDNumber']) if pd.notna(row['NationalIDNumber']) else None,\n",
    "                str(row['LoginID']) if pd.notna(row['LoginID']) else None,\n",
    "                str(row['OrganizationNode']) if pd.notna(row['OrganizationNode']) else None,\n",
    "                row['OrganizationLevel'] if pd.notna(row['OrganizationLevel']) else None,\n",
    "                str(row['JobTitle']) if pd.notna(row['JobTitle']) else None,\n",
    "                str(row['MaritalStatus']) if pd.notna(row['MaritalStatus']) else None,\n",
    "                str(row['Gender']) if pd.notna(row['Gender']) else None,\n",
    "                row['SalariedFlag'] if pd.notna(row['SalariedFlag']) else None,\n",
    "                row['VacationHours'] if pd.notna(row['VacationHours']) else None,\n",
    "                row['SickLeaveHours'] if pd.notna(row['SickLeaveHours']) else None,\n",
    "                row['CurrentFlag'] if pd.notna(row['CurrentFlag']) else None,\n",
    "                row['DepartmentID'] if pd.notna(row['DepartmentID']) else None,\n",
    "                row['ModifiedDate'] if pd.notna(row['ModifiedDate']) else None\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Fout bij EmployeeID {row['EmployeeID']}: {str(e)}\")\n",
    "            print(f\"Problematische rij data: {row.to_dict()}\")\n",
    "    \n",
    "    export_conn.commit()\n",
    "    print(f\"Eerste insert ronde voltooid. {len(final_df)} rijen toegevoegd.\")\n",
    "    \n",
    "    # Update manager relaties voor alle employees waar dit van toepassing is\n",
    "    for _, row in final_df.iterrows():\n",
    "        if pd.notna(row['manager_id']) and row['manager_id'] in all_employee_ids:\n",
    "            try:\n",
    "                export_cursor.execute(\"\"\"\n",
    "                    UPDATE Employee \n",
    "                    SET manager_id = ?\n",
    "                    WHERE EmployeeID = ?\n",
    "                \"\"\", \n",
    "                    row['manager_id'],\n",
    "                    row['EmployeeID']\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"Fout bij update manager voor EmployeeID {row['EmployeeID']}: {str(e)}\")\n",
    "    \n",
    "    export_conn.commit()\n",
    "    print(\"Manager relaties bijgewerkt.\")\n",
    "    \n",
    "    # Schakel de foreign key constraint weer in\n",
    "    try:\n",
    "        export_cursor.execute(\"ALTER TABLE Employee CHECK CONSTRAINT FK__Employee__manage__5BE2A6F2\")\n",
    "        export_conn.commit()\n",
    "        print(\"Foreign key constraint weer ingeschakeld\")\n",
    "        \n",
    "        # Valideer de constraints\n",
    "        export_cursor.execute(\"DBCC CHECKCONSTRAINTS('Employee')\")\n",
    "        result = export_cursor.fetchall()\n",
    "        if result:\n",
    "            print(\"Waarschuwing: Er zijn constraint violations gevonden:\")\n",
    "            for row in result:\n",
    "                print(row)\n",
    "        else:\n",
    "            print(\"Alle constraints zijn geldig\")\n",
    "    except Exception as e:\n",
    "        print(f\"Kon foreign key constraint niet inschakelen: {str(e)}\")\n",
    "    \n",
    "    \n",
    "\n",
    "move_employee()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ibrah\\AppData\\Local\\Temp\\ipykernel_9068\\1179525313.py:2: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql_query(\"SELECT * FROM EmployeeTerritories\", nconn)\n"
     ]
    }
   ],
   "source": [
    "def move_employee_territories():\n",
    "    df = pd.read_sql_query(\"SELECT * FROM EmployeeTerritories\", nconn)\n",
    "    for index, row in df.iterrows():\n",
    "        try:\n",
    "            query = \"\"\"\n",
    "            INSERT INTO EmployeeTerritories (\n",
    "                EmployeeID, TerritoryID\n",
    "            ) VALUES (?, ?)\n",
    "            \"\"\"\n",
    "            export_cursor.execute(query,\n",
    "                row['EmployeeID'],\n",
    "                row['TerritoryID']\n",
    "            )\n",
    "        except pyodbc.Error as e:\n",
    "            print(f\"Fout in EmployeeTerritories (EmployeeID: {row['EmployeeID']}, TerritoryID: {row['TerritoryID']}): {e}\")\n",
    "    export_conn.commit()\n",
    "move_employee_territories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_bonus():\n",
    "    df = pd.read_sql_query(\"SELECT * FROM Bonus\", aenconn)\n",
    "    for index, row in df.iterrows():\n",
    "        try:\n",
    "            query = \"\"\"\n",
    "            INSERT INTO Bonus (\n",
    "                Emp_id, Bonus_date, Bonus_amount\n",
    "            ) VALUES (?, ?, ?)\n",
    "            \"\"\"\n",
    "            export_cursor.execute(query,\n",
    "                row['emp_id'],\n",
    "                row['bonus_date'],\n",
    "                row['bonus_amount']\n",
    "            )\n",
    "        except pyodbc.Error as e:\n",
    "            print(f\"Fout in Bonus (Emp_id: {row['Emp_id']}): {e}\")\n",
    "    export_conn.commit()\n",
    "move_bonus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ibrah\\AppData\\Local\\Temp\\ipykernel_9068\\543909347.py:3: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  n_df = pd.read_sql_query(\"\"\"\n",
      "C:\\Users\\ibrah\\AppData\\Local\\Temp\\ipykernel_9068\\543909347.py:37: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_df = pd.concat([n_df, aen_df], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "def move_orders():\n",
    "    # Haal gegevens uit de eerste bron (nconn)\n",
    "    n_df = pd.read_sql_query(\"\"\"\n",
    "        SELECT \n",
    "            OrderID, CustomerID, EmployeeID, \n",
    "            OrderDate, RequiredDate, ShippedDate, \n",
    "            ShipVia, Freight, \n",
    "            ShipName, ShipAddress, ShipCity, \n",
    "            ShipRegion, ShipPostalCode, ShipCountry,\n",
    "            NULL AS Region, NULL AS Sales_rep\n",
    "        FROM dbo.Orders\n",
    "    \"\"\", nconn)\n",
    "    \n",
    "    # Haal gegevens uit de tweede bron (aenconn) met correcte mapping\n",
    "    aen_df = pd.read_sql_query(\"\"\"\n",
    "        SELECT \n",
    "            id AS OrderID, \n",
    "            cust_id AS CustomerID,  -- cust_id wordt gemapped naar CustomerID\n",
    "            sales_rep AS EmployeeID,  -- sales_rep wordt EmployeeID\n",
    "            order_date AS OrderDate,  -- order_date wordt OrderDate\n",
    "            NULL AS RequiredDate, \n",
    "            NULL AS ShippedDate,\n",
    "            NULL AS ShipVia, \n",
    "            NULL AS Freight,\n",
    "            NULL AS ShipName, \n",
    "            NULL AS ShipAddress, \n",
    "            NULL AS ShipCity,\n",
    "            region AS ShipRegion, \n",
    "            NULL AS ShipPostalCode, \n",
    "            NULL AS ShipCountry,\n",
    "            region AS Region, \n",
    "            sales_rep AS Sales_rep\n",
    "        FROM Sales_Order\n",
    "    \"\"\", aenconn)\n",
    "    \n",
    "    # Combineer beide dataframes\n",
    "    combined_df = pd.concat([n_df, aen_df], ignore_index=True)\n",
    "    \n",
    "    # Verwijder mogelijke duplicates op OrderID\n",
    "    final_df = combined_df.drop_duplicates(subset=['OrderID'], keep='first')\n",
    "    \n",
    "    # Insert logica\n",
    "    for _, row in final_df.iterrows():\n",
    "        try:\n",
    "            export_cursor.execute(\"\"\"\n",
    "                INSERT INTO [Order] (\n",
    "                    OrderID, CustomerID, EmployeeID, \n",
    "                    OrderDate, RequiredDate, ShippedDate,\n",
    "                    ShipVia, Freight, ShipName, ShipAdress,\n",
    "                    ShipCity, ShipPostalCode, ShipCountry,\n",
    "                    Region, Sales_rep\n",
    "                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "            \"\"\", \n",
    "                row['OrderID'],\n",
    "                row['CustomerID'] if pd.notna(row['CustomerID']) else None,\n",
    "                row['EmployeeID'] if pd.notna(row['EmployeeID']) else None,\n",
    "                row['OrderDate'] if pd.notna(row['OrderDate']) else None,\n",
    "                row['RequiredDate'] if pd.notna(row['RequiredDate']) else None,\n",
    "                row['ShippedDate'] if pd.notna(row['ShippedDate']) else None,\n",
    "                row['ShipVia'] if pd.notna(row['ShipVia']) else None,\n",
    "                float(row['Freight']) if pd.notna(row['Freight']) else None,\n",
    "                str(row['ShipName']) if pd.notna(row['ShipName']) else None,\n",
    "                str(row['ShipAddress']) if pd.notna(row['ShipAddress']) else None,\n",
    "                str(row['ShipCity']) if pd.notna(row['ShipCity']) else None,\n",
    "                str(row['ShipPostalCode']) if pd.notna(row['ShipPostalCode']) else None,\n",
    "                str(row['ShipCountry']) if pd.notna(row['ShipCountry']) else None,\n",
    "                str(row['Region']) if pd.notna(row['Region']) else None,\n",
    "                row['Sales_rep'] if pd.notna(row['Sales_rep']) else None\n",
    "            )\n",
    "        except pyodbc.Error as e:\n",
    "            print(f\"Fout bij OrderID {row['OrderID']}: {str(e)}\")\n",
    "            print(f\"Problematische rij data: {row.to_dict()}\")\n",
    "    \n",
    "    export_conn.commit()\n",
    "    \n",
    "move_orders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ibrah\\AppData\\Local\\Temp\\ipykernel_9068\\2567412267.py:2: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql_query(\"SELECT * FROM [Order Details]\", nconn)\n"
     ]
    }
   ],
   "source": [
    "def move_order_details():\n",
    "    df = pd.read_sql_query(\"SELECT * FROM [Order Details]\", nconn)\n",
    "    for index, row in df.iterrows():\n",
    "        try:\n",
    "            query = \"\"\"\n",
    "            INSERT INTO Order_Details (\n",
    "                OrderID, ProductID, UnitPrice, Quantity, Discount\n",
    "            ) VALUES (?, ?, ?, ?, ?)\n",
    "            \"\"\"\n",
    "            export_cursor.execute(query,\n",
    "                row['OrderID'],\n",
    "                row['ProductID'],\n",
    "                row['UnitPrice'],\n",
    "                row['Quantity'],\n",
    "                row['Discount']\n",
    "            )\n",
    "        except pyodbc.Error as e:\n",
    "            print(f\"Fout in Order_Details (OrderID: {row['OrderID']}, ProductID: {row['ProductID']}): {e}\")\n",
    "    export_conn.commit()\n",
    "\n",
    "move_order_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_sales_order_item():\n",
    "    df = pd.read_sql_query(\"SELECT * FROM Sales_Order_Item\", aenconn)\n",
    "    for index, row in df.iterrows():\n",
    "        try:\n",
    "            query = \"\"\"\n",
    "            INSERT INTO Sales_Order_Item (\n",
    "                Id, Line_id, Prod_id, Quantity, Ship_date\n",
    "            ) VALUES (?, ?, ?, ?, ?)\n",
    "            \"\"\"\n",
    "            export_cursor.execute(query,\n",
    "                row['id'],\n",
    "                row['line_id'],\n",
    "                row['prod_id'],\n",
    "                row['quantity'],\n",
    "                row['ship_date']\n",
    "            )\n",
    "        except pyodbc.Error as e:\n",
    "            print(f\"Fout in Sales_Order_Item (Id: {row['Id']}, Line_id: {row['Line_id']}): {e}\")\n",
    "    export_conn.commit()\n",
    "move_sales_order_item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_purchasing_vendor():\n",
    "    df = pd.read_sql_query(\"SELECT * FROM Purchasing_Vendor\", advconn)\n",
    "    for index, row in df.iterrows():\n",
    "        try:\n",
    "            query = \"\"\"\n",
    "            INSERT INTO Purchasing_Vendor (\n",
    "                BusinessEntityID, AccountNumber, Name, CreditRating,\n",
    "                PreferredVendorStatus, ActiveFlag, PurchasingWebServiceURL, ModifiedDate\n",
    "            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?)\n",
    "            \"\"\"\n",
    "            export_cursor.execute(query,\n",
    "                row['BusinessEntityID'],\n",
    "                row['AccountNumber'],\n",
    "                row['Name'],\n",
    "                row['CreditRating'],\n",
    "                row['PreferredVendorStatus'],\n",
    "                row['ActiveFlag'],\n",
    "                row['PurchasingWebServiceURL'],\n",
    "                row['ModifiedDate']\n",
    "            )\n",
    "        except pyodbc.Error as e:\n",
    "            print(f\"Fout in Purchasing_Vendor (BusinessEntityID: {row['BusinessEntityID']}): {e}\")\n",
    "    export_conn.commit()\n",
    "\n",
    "def move_purchasing_purchase_order_header():\n",
    "    df = pd.read_sql_query(\"SELECT * FROM Purchasing_PurchaseOrderHeader\", advconn)\n",
    "    for index, row in df.iterrows():\n",
    "        try:\n",
    "            query = \"\"\"\n",
    "            INSERT INTO Purchasing_PurchaseOrderHeader (\n",
    "                PurchaseOrderID, RevisionNumber, Status, EmployeeID,\n",
    "                VendorID, ShipMethodID, OrderDate, ShipDate,\n",
    "                SubTotal, TaxAmt, Freight, TotalDue, ModifiedDate\n",
    "            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "            \"\"\"\n",
    "            export_cursor.execute(query,\n",
    "                row['PurchaseOrderID'],\n",
    "                row['RevisionNumber'],\n",
    "                row['Status'],\n",
    "                row['EmployeeID'],\n",
    "                row['VendorID'],\n",
    "                row['ShipMethodID'],\n",
    "                row['OrderDate'],\n",
    "                row['ShipDate'],\n",
    "                row['SubTotal'],\n",
    "                row['TaxAmt'],\n",
    "                row['Freight'],\n",
    "                row['TotalDue'],\n",
    "                row['ModifiedDate']\n",
    "            )\n",
    "        except pyodbc.Error as e:\n",
    "            print(f\"Fout in Purchasing_PurchaseOrderHeader (PurchaseOrderID: {row['PurchaseOrderID']}): {e}\")\n",
    "    export_conn.commit()\n",
    "\n",
    "def move_purchasing_purchase_order_detail():\n",
    "    df = pd.read_sql_query(\"SELECT * FROM Purchasing_PurchaseOrderDetail\", advconn)\n",
    "    for index, row in df.iterrows():\n",
    "        try:\n",
    "            query = \"\"\"\n",
    "            INSERT INTO Purchasing_PurchaseOrderDetail (\n",
    "                PurchaseOrderDetailID, PurchaseOrderID, DueDate, OrderQty,\n",
    "                ProductID, UnitPrice, LineTotal, ReceivedQty,\n",
    "                RejectedQty, StockedQty, ModifiedDate\n",
    "            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "            \"\"\"\n",
    "            export_cursor.execute(query,\n",
    "                row['PurchaseOrderDetailID'],\n",
    "                row['PurchaseOrderID'],\n",
    "                row['DueDate'],\n",
    "                row['OrderQty'],\n",
    "                row['ProductID'],\n",
    "                row['UnitPrice'],\n",
    "                row['LineTotal'],\n",
    "                row['ReceivedQty'],\n",
    "                row['RejectedQty'],\n",
    "                row['StockedQty'],\n",
    "                row['ModifiedDate']\n",
    "            )\n",
    "        except pyodbc.Error as e:\n",
    "            print(f\"Fout in Purchasing_PurchaseOrderDetail (PurchaseOrderDetailID: {row['PurchaseOrderDetailID']}): {e}\")\n",
    "    export_conn.commit()\n",
    "\n",
    "move_purchasing_vendor()\n",
    "move_purchasing_purchase_order_header()\n",
    "move_purchasing_purchase_order_detail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_cursor.close()\n",
    "export_conn.close()\n",
    "nconn_cursor.close()\n",
    "nconn.close()\n",
    "aenconn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
